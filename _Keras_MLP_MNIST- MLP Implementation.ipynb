{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWWn1oMdMP0d"
   },
   "source": [
    "MLP for Complex Problems: The MNIST dataset\n",
    "=========\n",
    "\n",
    "\n",
    "In this exercise we will first learn to use the simple perceptron network (input-output layers only) and a Multi-Layer Perceptron (MLP, with one or more hidden layers). To make the task more interesting than the XOR problem, we will be using a more complex training set. This will be the MNIST dataset, a well known neural network problem for the recognition of the 10 handwritten characters from 0 to 9 ([MNIST](http://yann.lecun.com/exdb/mnist/)).\n",
    "\n",
    "This exercise is based on the  Gulli & Pal (2017) 'Deep Learning with Keras' textbook, with some additional code to help us understand and test the programme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezwPEU5UMP0o"
   },
   "source": [
    "**Importing the libraries and defining the main training parameters**\n",
    "\n",
    "The initial code is necessary to prepare the data and the simulation (hyper)parameters.\n",
    "We first import numpy. In our case we will use it to create and pre-process the array of the training data sets. We then import a few functions from Keras (we used some of these in our previous XOR exercise). The matplotlib library will be used for visualising some MNIST images and the plot of the training results.\n",
    "\n",
    "The code also defines the variables for some of the main parameters used throughout this program. \n",
    "The random seed definition is also important to be able to repeat the same parameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpM98ckGMP0u",
    "outputId": "544d28f2-2cf1-4b4d-e258-58382f188f51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# import of numpy and keras libraries\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# variables for network and training\n",
    "N_EPOCH = 200 # initially set at 200 ; you can change this later \n",
    "BATCH_SIZE = 128  \n",
    "VERBOSE = 1\n",
    "N_CLASSES = 10   # number of classes/categories of digits from 0 to 9, i.e. number of output units \n",
    "OPTIMIZER = SGD(lr=0.1) # Stochastic gradient descent optimiser\n",
    "N_HIDDEN = 128   # number of hidden units\n",
    "VALIDATION_SPLIT=0.2 # proportion of the dataset used for validation, with remaining .8 for training \n",
    "\n",
    "#each 2D image consists of 28x28 values/pixels, which needs to be reshaped in a vector of 784 pixels\n",
    "RESHAPED = 784\n",
    "\n",
    "# random seed number to be used for reproducibility\n",
    "np.random.seed(1671)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rgZEImMMP08"
   },
   "source": [
    "**Preparing the MNIST dataset and visualising the input images**\n",
    "\n",
    "This part of the code prepares the input and output training set, and the corresponding test sets. \n",
    "It also visualises a sample image. The MNIST dataset is included in the Keras program and we do not need to use and external file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l4-TuW2_MP0-",
    "outputId": "b8b8963e-8cef-4756-830b-b12fefa5c835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data input shape:  (60000, 28, 28)\n",
      "Training data output shape:  (60000,)\n",
      "Test data input shape:  (10000, 28, 28)\n",
      "Test data ouput shape:  (10000,)\n",
      "Sample input image: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  67 232  39   0   0   0   0   0]\n",
      " [  0   0   0   0  62  81   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 120 180  39   0   0   0   0   0]\n",
      " [  0   0   0   0 126 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   2 153 210  40   0   0   0   0   0]\n",
      " [  0   0   0   0 220 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  27 254 162   0   0   0   0   0   0]\n",
      " [  0   0   0   0 222 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 183 254 125   0   0   0   0   0   0]\n",
      " [  0   0   0  46 245 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 198 254  56   0   0   0   0   0   0]\n",
      " [  0   0   0 120 254 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   23 231 254  29   0   0   0   0   0   0]\n",
      " [  0   0   0 159 254 120   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  163 254 216  16   0   0   0   0   0   0]\n",
      " [  0   0   0 159 254  67   0   0   0   0   0   0   0   0   0  14  86 178\n",
      "  248 254  91   0   0   0   0   0   0   0]\n",
      " [  0   0   0 159 254  85   0   0   0  47  49 116 144 150 241 243 234 179\n",
      "  241 252  40   0   0   0   0   0   0   0]\n",
      " [  0   0   0 150 253 237 207 207 207 253 254 250 240 198 143  91  28   5\n",
      "  233 250   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 119 177 177 177 177 177  98  56   0   0   0   0   0 102\n",
      "  254 220   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  254 137   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  254  57   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  254  57   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  255  94   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  254  96   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  254 153   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  255 153   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  96\n",
      "  254 153   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM6klEQVR4nO3db4hd9Z3H8c8n2oDYKol/0sEETUuUliXqEmXVolliQzZPYh9YGrRmqTiCFVrYByv2QQVZ0MW29ImFqUrSNWspxNFQam0IRVvQMBNJNcmYxIYYJxmSFZGmKHaj330wZ7pjnHvu5N5z7rkz3/cLLvfe873nni+HfPI755575+eIEID5b0HTDQDoDcIOJEHYgSQIO5AEYQeSOLeXG7PNR/9AzSLCMy3vamS3vc72Adtv2X6gm/cCUC93ep3d9jmSDkr6uqRxSSOSNkbE/pJ1GNmBmtUxsl8v6a2IOBwRf5P0S0kbung/ADXqJuyXSXpn2vPxYtmn2B60PWp7tIttAehSNx/QzXSo8JnD9IgYkjQkcRgPNKmbkX1c0rJpz5dKOt5dOwDq0k3YRyStsL3c9kJJ35K0vZq2AFSt48P4iDht+35JL0o6R9JTEbGvss4AVKrjS28dbYxzdqB2tXypBsDcQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASHU/ZDPS7NWvWtKxt3bq1dN1bbrmltH7gwIGOempSV2G3fUTSKUkfSzodEauqaApA9aoY2f85It6t4H0A1IhzdiCJbsMekn5ne7ftwZleYHvQ9qjt0S63BaAL3R7G3xQRx21fKmmH7Tcj4uXpL4iIIUlDkmQ7utwegA51NbJHxPHi/qSkYUnXV9EUgOp1HHbb59v+wtRjSWsl7a2qMQDV6uYwfomkYdtT7/PfEfHbSrqqwc0331xav+iii0rrw8PDVbaDHrjuuuta1kZGRnrYSX/oOOwRcVjS1RX2AqBGXHoDkiDsQBKEHUiCsANJEHYgiTQ/cV29enVpfcWKFaV1Lr31nwULyseq5cuXt6xdfvnlpesWl5TnFUZ2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUgizXX2u+66q7T+yiuv9KgTVGVgYKC0fs8997SsPf3006Xrvvnmmx311M8Y2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiTTX2dv99hlzzxNPPNHxuocOHaqwk7mBBABJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEvPmOvvKlStL60uWLOlRJ+iVCy+8sON1d+zYUWEnc0Pbkd32U7ZP2t47bdli2ztsHyruF9XbJoBuzeYwfrOkdWcse0DSzohYIWln8RxAH2sb9oh4WdJ7ZyzeIGlL8XiLpNuqbQtA1To9Z18SEROSFBETti9t9ULbg5IGO9wOgIrU/gFdRAxJGpIk21H39gDMrNNLbydsD0hScX+yupYA1KHTsG+XtKl4vEnS89W0A6AubQ/jbT8jabWki22PS/qhpEck/cr23ZKOSrq9ziZnY/369aX18847r0edoCrtvhtRNv96O8eOHet43bmqbdgjYmOL0pqKewFQI74uCyRB2IEkCDuQBGEHkiDsQBLz5ieuV111VVfr79u3r6JOUJXHHnustN7u0tzBgwdb1k6dOtVRT3MZIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDFvrrN3a2RkpOkW5qQLLrigtL5u3Zl/q/T/3XnnnaXrrl27tqOepjz88MMta++//35X7z0XMbIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJcZy8sXry4sW1fffXVpXXbpfVbb721ZW3p0qWl6y5cuLC0fscdd5TWFywoHy8+/PDDlrVdu3aVrvvRRx+V1s89t/yf7+7du0vr2TCyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjojebcyubWOPP/54af3ee+8trbf7ffPRo0fPtqVZW7lyZWm93XX206dPt6x98MEHpevu37+/tN7uWvjo6Ghp/aWXXmpZO3HiROm64+PjpfVFixaV1tt9h2C+iogZ/8G0HdltP2X7pO2905Y9ZPuY7T3FrXxydACNm81h/GZJM/25kZ9ExDXF7TfVtgWgam3DHhEvS3qvB70AqFE3H9Ddb/v14jC/5cmT7UHbo7bLT+4A1KrTsP9M0pclXSNpQtKPWr0wIoYiYlVErOpwWwAq0FHYI+JERHwcEZ9I+rmk66ttC0DVOgq77YFpT78haW+r1wLoD21/z277GUmrJV1se1zSDyWttn2NpJB0RFL5ReweuO+++0rrb7/9dmn9xhtvrLKds9LuGv5zzz1XWh8bG2tZe/XVVztpqScGBwdL65dccklp/fDhw1W2M++1DXtEbJxh8ZM19AKgRnxdFkiCsANJEHYgCcIOJEHYgSTS/CnpRx99tOkWcIY1a9Z0tf62bdsq6iQHRnYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNdXbMP8PDw023MKcwsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/J4dfct2af3KK68srffzdNVNaDuy215m+/e2x2zvs/29Yvli2ztsHyruF9XfLoBOzeYw/rSkf4uIr0j6J0nftf1VSQ9I2hkRKyTtLJ4D6FNtwx4RExHxWvH4lKQxSZdJ2iBpS/GyLZJuq6lHABU4q3N221dIulbSLklLImJCmvwPwfalLdYZlDTYZZ8AujTrsNv+vKRtkr4fEX9p9+HJlIgYkjRUvEd00iSA7s3q0pvtz2ky6Fsj4tli8QnbA0V9QNLJeloEUIXZfBpvSU9KGouIH08rbZe0qXi8SdLz1beHzCKi9LZgwYLSGz5tNofxN0n6tqQ3bO8plj0o6RFJv7J9t6Sjkm6vpUMAlWgb9oj4o6RWJ+hrqm0HQF041gGSIOxAEoQdSIKwA0kQdiAJfuKKOeuGG24orW/evLk3jcwRjOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATX2dG3ZvvXkDA7jOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATX2dGYF154obR+++38dfIqMbIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKOiPIX2Msk/ULSFyV9ImkoIn5q+yFJ90j6n+KlD0bEb9q8V/nGAHQtImb8QwCzCfuApIGIeM32FyTtlnSbpG9K+mtEPDbbJgg7UL9WYZ/N/OwTkiaKx6dsj0m6rNr2ANTtrM7ZbV8h6VpJu4pF99t+3fZTthe1WGfQ9qjt0e5aBdCNtofxf3+h/XlJL0n6j4h41vYSSe9KCkkPa/JQ/ztt3oPDeKBmHZ+zS5Ltz0n6taQXI+LHM9SvkPTriPiHNu9D2IGatQp728N4T/6JzycljU0PevHB3ZRvSNrbbZMA6jObT+O/JukPkt7Q5KU3SXpQ0kZJ12jyMP6IpHuLD/PK3ouRHahZV4fxVSHsQP06PowHMD8QdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuj1lM3vSnp72vOLi2X9qF9769e+JHrrVJW9Xd6q0NPfs39m4/ZoRKxqrIES/dpbv/Yl0VunetUbh/FAEoQdSKLpsA81vP0y/dpbv/Yl0VunetJbo+fsAHqn6ZEdQI8QdiCJRsJue53tA7bfsv1AEz20YvuI7Tds72l6frpiDr2TtvdOW7bY9g7bh4r7GefYa6i3h2wfK/bdHtvrG+ptme3f2x6zvc/294rlje67kr56st96fs5u+xxJByV9XdK4pBFJGyNif08bacH2EUmrIqLxL2DYvlnSXyX9YmpqLdv/Kem9iHik+I9yUUT8e5/09pDOchrvmnprNc34v6rBfVfl9OedaGJkv17SWxFxOCL+JumXkjY00Effi4iXJb13xuINkrYUj7do8h9Lz7XorS9ExEREvFY8PiVpaprxRvddSV890UTYL5P0zrTn4+qv+d5D0u9s77Y92HQzM1gyNc1WcX9pw/2cqe003r10xjTjfbPvOpn+vFtNhH2mqWn66frfTRHxj5L+RdJ3i8NVzM7PJH1Zk3MATkj6UZPNFNOMb5P0/Yj4S5O9TDdDXz3Zb02EfVzSsmnPl0o63kAfM4qI48X9SUnDmjzt6CcnpmbQLe5PNtzP30XEiYj4OCI+kfRzNbjvimnGt0naGhHPFosb33cz9dWr/dZE2EckrbC93PZCSd+StL2BPj7D9vnFByeyfb6kteq/qai3S9pUPN4k6fkGe/mUfpnGu9U042p43zU+/XlE9Pwmab0mP5H/s6QfNNFDi76+JOlPxW1f071JekaTh3X/q8kjorslXSRpp6RDxf3iPurtvzQ5tffrmgzWQEO9fU2Tp4avS9pT3NY3ve9K+urJfuPrskASfIMOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4P2DL5W+TMVx6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# data: shuffled and split between train and test sets, loading and using the Keras mnist dataset\n",
    "(input_X_train, output_Y_train), (input_X_test, output_Y_test) = mnist.load_data()\n",
    "\n",
    "# print the shapes of the input and output data\n",
    "print(\"Training data input shape: \" , input_X_train.shape)\n",
    "print(\"Training data output shape: \" , output_Y_train.shape)\n",
    "print(\"Test data input shape: \" , input_X_test.shape)\n",
    "print(\"Test data ouput shape: \" , output_Y_test.shape)\n",
    "\n",
    "# visualisation of the numerical vector and plot of a selected image\n",
    "Selected_Image = 2\n",
    "image = input_X_train[Selected_Image]\n",
    "print (\"Sample input image: \" + str(image))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDqNl3taMP1P"
   },
   "source": [
    "The input images now have to be reshaped as a linear vector. That is, we go from a 2D image of 28x28 pixels, to a linear vector of 784 (i.e. 28*28) pixels, to be passed as the 784 input units. Moreover, the initial pixel grey values given as type __int__ in the range 0-255 will be normalised to the __float32__ type in the range 0-1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fB15FrXOMP1R",
    "outputId": "14bb70d3-2633-4eec-f783-f751c42ba407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data ready\n"
     ]
    }
   ],
   "source": [
    "# use 60000 images for training, 10000 for validation test\n",
    "input_X_train = input_X_train.reshape(60000, RESHAPED)\n",
    "input_X_test = input_X_test.reshape(10000, RESHAPED)\n",
    "input_X_train = input_X_train.astype('float32')\n",
    "input_X_test = input_X_test.astype('float32')\n",
    "\n",
    "# normalisation of the pixel values from 0-255 range to 0-1 range \n",
    "input_X_train /= 255\n",
    "input_X_test /= 255\n",
    "\n",
    "print (\"Input data ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsCwC5y7MP1Z"
   },
   "source": [
    "**Preparing the output labels**\n",
    "\n",
    "This code converts the output data into categorical (one-hot encoding) vectors of 0s and 1s.\n",
    "See example of the visualisation of the one-hot vector for the selected image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc4dgAqqMP1c",
    "outputId": "98b2e61e-92a5-4ea9-de99-97b57eefefc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot-vector: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "output_Y_train = utils.to_categorical(output_Y_train, N_CLASSES)\n",
    "output_Y_test = utils.to_categorical(output_Y_test, N_CLASSES)\n",
    "\n",
    "# print the categorical, one-hot output vector for the sample image\n",
    "label = output_Y_train[Selected_Image]\n",
    "print (\"One-hot-vector: \" + str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-rcBfv8MP1q"
   },
   "source": [
    "Training the Simple Perceptron\n",
    "=========\n",
    "\n",
    "**Defining the network: Simple Perceptron**\n",
    "\n",
    "We will start by training a simple perceptron, i.e. a network with an input layer (the 784 input values/pixels) connected to the output layer (the 10 number classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTb4RC7zMP1s",
    "outputId": "eba814ce-d129-4213-f729-0a5b83a0fd97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defaults sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Dense layer for all to all connections\n",
    "# Define the output layer with 10 output units, and softmax activation as categorical output\n",
    "model.add(Dense(N_CLASSES, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Use categorical crossentropy for the loss evaluation, and the accuracy metrics\n",
    "# we previously chose the SGD optimiser in the OPTIMIZER variable definition  \n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "\n",
    "#show the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHyq0YoRMP1y"
   },
   "source": [
    "**Let's train the simple perceptron network**\n",
    "\n",
    "Let's now train (fit) the network with the above-defined batch size (128), and number of epochs (200). We save the training results into the history variable.\n",
    "\n",
    "Here we use the previous __VALIDATION_SPLIT=0.2__ definition to split the dataset into a 20% (0.2) validation set and the remaning 80% as training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lg3RCFukMP10",
    "outputId": "af12683c-9bac-43aa-f219-522e7c694317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6253 - accuracy: 0.8444 - val_loss: 0.3968 - val_accuracy: 0.8957\n",
      "Epoch 2/200\n",
      "375/375 [==============================] - 0s 923us/step - loss: 0.3960 - accuracy: 0.8927 - val_loss: 0.3491 - val_accuracy: 0.9056\n",
      "Epoch 3/200\n",
      "375/375 [==============================] - 0s 912us/step - loss: 0.3593 - accuracy: 0.9004 - val_loss: 0.3282 - val_accuracy: 0.9089\n",
      "Epoch 4/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.3404 - accuracy: 0.9057 - val_loss: 0.3168 - val_accuracy: 0.9112\n",
      "Epoch 5/200\n",
      "375/375 [==============================] - 0s 909us/step - loss: 0.3281 - accuracy: 0.9083 - val_loss: 0.3092 - val_accuracy: 0.9140\n",
      "Epoch 6/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.3194 - accuracy: 0.9110 - val_loss: 0.3024 - val_accuracy: 0.9162\n",
      "Epoch 7/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.3128 - accuracy: 0.9134 - val_loss: 0.2996 - val_accuracy: 0.9154\n",
      "Epoch 8/200\n",
      "375/375 [==============================] - 0s 948us/step - loss: 0.3075 - accuracy: 0.9144 - val_loss: 0.2935 - val_accuracy: 0.9184\n",
      "Epoch 9/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.3031 - accuracy: 0.9154 - val_loss: 0.2917 - val_accuracy: 0.9187\n",
      "Epoch 10/200\n",
      "375/375 [==============================] - 0s 926us/step - loss: 0.2994 - accuracy: 0.9161 - val_loss: 0.2891 - val_accuracy: 0.9194\n",
      "Epoch 11/200\n",
      "375/375 [==============================] - 0s 960us/step - loss: 0.2963 - accuracy: 0.9176 - val_loss: 0.2860 - val_accuracy: 0.9194\n",
      "Epoch 12/200\n",
      "375/375 [==============================] - 0s 944us/step - loss: 0.2935 - accuracy: 0.9181 - val_loss: 0.2861 - val_accuracy: 0.9191\n",
      "Epoch 13/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2911 - accuracy: 0.9182 - val_loss: 0.2841 - val_accuracy: 0.9206\n",
      "Epoch 14/200\n",
      "375/375 [==============================] - 0s 987us/step - loss: 0.2890 - accuracy: 0.9192 - val_loss: 0.2823 - val_accuracy: 0.9209\n",
      "Epoch 15/200\n",
      "375/375 [==============================] - 0s 971us/step - loss: 0.2870 - accuracy: 0.9197 - val_loss: 0.2812 - val_accuracy: 0.9213\n",
      "Epoch 16/200\n",
      "375/375 [==============================] - 0s 960us/step - loss: 0.2851 - accuracy: 0.9200 - val_loss: 0.2794 - val_accuracy: 0.9219\n",
      "Epoch 17/200\n",
      "375/375 [==============================] - 0s 943us/step - loss: 0.2834 - accuracy: 0.9215 - val_loss: 0.2785 - val_accuracy: 0.9219\n",
      "Epoch 18/200\n",
      "375/375 [==============================] - 0s 965us/step - loss: 0.2820 - accuracy: 0.9212 - val_loss: 0.2779 - val_accuracy: 0.9222\n",
      "Epoch 19/200\n",
      "375/375 [==============================] - 0s 941us/step - loss: 0.2806 - accuracy: 0.9217 - val_loss: 0.2766 - val_accuracy: 0.9227\n",
      "Epoch 20/200\n",
      "375/375 [==============================] - 0s 945us/step - loss: 0.2790 - accuracy: 0.9222 - val_loss: 0.2777 - val_accuracy: 0.9220\n",
      "Epoch 21/200\n",
      "375/375 [==============================] - 0s 938us/step - loss: 0.2779 - accuracy: 0.9224 - val_loss: 0.2760 - val_accuracy: 0.9222\n",
      "Epoch 22/200\n",
      "375/375 [==============================] - 0s 909us/step - loss: 0.2768 - accuracy: 0.9228 - val_loss: 0.2759 - val_accuracy: 0.9225\n",
      "Epoch 23/200\n",
      "375/375 [==============================] - 0s 922us/step - loss: 0.2759 - accuracy: 0.9226 - val_loss: 0.2745 - val_accuracy: 0.9226\n",
      "Epoch 24/200\n",
      "375/375 [==============================] - 0s 941us/step - loss: 0.2748 - accuracy: 0.9231 - val_loss: 0.2745 - val_accuracy: 0.9232\n",
      "Epoch 25/200\n",
      "375/375 [==============================] - 0s 941us/step - loss: 0.2740 - accuracy: 0.9240 - val_loss: 0.2734 - val_accuracy: 0.9239\n",
      "Epoch 26/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2730 - accuracy: 0.9237 - val_loss: 0.2727 - val_accuracy: 0.9233\n",
      "Epoch 27/200\n",
      "375/375 [==============================] - 0s 922us/step - loss: 0.2721 - accuracy: 0.9243 - val_loss: 0.2733 - val_accuracy: 0.9244\n",
      "Epoch 28/200\n",
      "375/375 [==============================] - 0s 936us/step - loss: 0.2714 - accuracy: 0.9241 - val_loss: 0.2718 - val_accuracy: 0.9243\n",
      "Epoch 29/200\n",
      "375/375 [==============================] - 0s 955us/step - loss: 0.2707 - accuracy: 0.9239 - val_loss: 0.2717 - val_accuracy: 0.9250\n",
      "Epoch 30/200\n",
      "375/375 [==============================] - 0s 963us/step - loss: 0.2698 - accuracy: 0.9248 - val_loss: 0.2719 - val_accuracy: 0.9254\n",
      "Epoch 31/200\n",
      "375/375 [==============================] - 0s 944us/step - loss: 0.2691 - accuracy: 0.9248 - val_loss: 0.2713 - val_accuracy: 0.9247\n",
      "Epoch 32/200\n",
      "375/375 [==============================] - 0s 949us/step - loss: 0.2684 - accuracy: 0.9250 - val_loss: 0.2717 - val_accuracy: 0.9258\n",
      "Epoch 33/200\n",
      "375/375 [==============================] - 0s 939us/step - loss: 0.2679 - accuracy: 0.9250 - val_loss: 0.2706 - val_accuracy: 0.9243\n",
      "Epoch 34/200\n",
      "375/375 [==============================] - 0s 937us/step - loss: 0.2673 - accuracy: 0.9255 - val_loss: 0.2699 - val_accuracy: 0.9250\n",
      "Epoch 35/200\n",
      "375/375 [==============================] - 0s 935us/step - loss: 0.2666 - accuracy: 0.9259 - val_loss: 0.2697 - val_accuracy: 0.9249\n",
      "Epoch 36/200\n",
      "375/375 [==============================] - 0s 921us/step - loss: 0.2661 - accuracy: 0.9258 - val_loss: 0.2697 - val_accuracy: 0.9258\n",
      "Epoch 37/200\n",
      "375/375 [==============================] - 0s 930us/step - loss: 0.2654 - accuracy: 0.9262 - val_loss: 0.2698 - val_accuracy: 0.9243\n",
      "Epoch 38/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2648 - accuracy: 0.9261 - val_loss: 0.2697 - val_accuracy: 0.9258\n",
      "Epoch 39/200\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2644 - accuracy: 0.9264 - val_loss: 0.2695 - val_accuracy: 0.9252\n",
      "Epoch 40/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2638 - accuracy: 0.9268 - val_loss: 0.2697 - val_accuracy: 0.9255\n",
      "Epoch 41/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2633 - accuracy: 0.9266 - val_loss: 0.2695 - val_accuracy: 0.9255\n",
      "Epoch 42/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2628 - accuracy: 0.9264 - val_loss: 0.2691 - val_accuracy: 0.9259\n",
      "Epoch 43/200\n",
      "375/375 [==============================] - 0s 934us/step - loss: 0.2625 - accuracy: 0.9267 - val_loss: 0.2683 - val_accuracy: 0.9256\n",
      "Epoch 44/200\n",
      "375/375 [==============================] - 0s 922us/step - loss: 0.2620 - accuracy: 0.9268 - val_loss: 0.2693 - val_accuracy: 0.9252\n",
      "Epoch 45/200\n",
      "375/375 [==============================] - 0s 935us/step - loss: 0.2617 - accuracy: 0.9271 - val_loss: 0.2690 - val_accuracy: 0.9253\n",
      "Epoch 46/200\n",
      "375/375 [==============================] - 0s 951us/step - loss: 0.2613 - accuracy: 0.9272 - val_loss: 0.2682 - val_accuracy: 0.9262\n",
      "Epoch 47/200\n",
      "375/375 [==============================] - 0s 916us/step - loss: 0.2606 - accuracy: 0.9278 - val_loss: 0.2691 - val_accuracy: 0.9257\n",
      "Epoch 48/200\n",
      "375/375 [==============================] - 0s 995us/step - loss: 0.2603 - accuracy: 0.9270 - val_loss: 0.2684 - val_accuracy: 0.9262\n",
      "Epoch 49/200\n",
      "375/375 [==============================] - 0s 952us/step - loss: 0.2599 - accuracy: 0.9273 - val_loss: 0.2676 - val_accuracy: 0.9264\n",
      "Epoch 50/200\n",
      "375/375 [==============================] - 0s 932us/step - loss: 0.2597 - accuracy: 0.9277 - val_loss: 0.2680 - val_accuracy: 0.9278\n",
      "Epoch 51/200\n",
      "375/375 [==============================] - 0s 947us/step - loss: 0.2591 - accuracy: 0.9284 - val_loss: 0.2687 - val_accuracy: 0.9269\n",
      "Epoch 52/200\n",
      "375/375 [==============================] - 0s 947us/step - loss: 0.2589 - accuracy: 0.9277 - val_loss: 0.2682 - val_accuracy: 0.9273\n",
      "Epoch 53/200\n",
      "375/375 [==============================] - 0s 924us/step - loss: 0.2583 - accuracy: 0.9283 - val_loss: 0.2674 - val_accuracy: 0.9265\n",
      "Epoch 54/200\n",
      "375/375 [==============================] - 0s 939us/step - loss: 0.2583 - accuracy: 0.9286 - val_loss: 0.2680 - val_accuracy: 0.9262\n",
      "Epoch 55/200\n",
      "375/375 [==============================] - 0s 957us/step - loss: 0.2578 - accuracy: 0.9280 - val_loss: 0.2674 - val_accuracy: 0.9278\n",
      "Epoch 56/200\n",
      "375/375 [==============================] - 0s 947us/step - loss: 0.2575 - accuracy: 0.9285 - val_loss: 0.2669 - val_accuracy: 0.9273\n",
      "Epoch 57/200\n",
      "375/375 [==============================] - 0s 960us/step - loss: 0.2571 - accuracy: 0.9283 - val_loss: 0.2678 - val_accuracy: 0.9276\n",
      "Epoch 58/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2568 - accuracy: 0.9284 - val_loss: 0.2678 - val_accuracy: 0.9268\n",
      "Epoch 59/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2565 - accuracy: 0.9284 - val_loss: 0.2671 - val_accuracy: 0.9269\n",
      "Epoch 60/200\n",
      "375/375 [==============================] - 0s 955us/step - loss: 0.2562 - accuracy: 0.9282 - val_loss: 0.2665 - val_accuracy: 0.9277\n",
      "Epoch 61/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2559 - accuracy: 0.9289 - val_loss: 0.2660 - val_accuracy: 0.9277\n",
      "Epoch 62/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2556 - accuracy: 0.9287 - val_loss: 0.2669 - val_accuracy: 0.9276\n",
      "Epoch 63/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2554 - accuracy: 0.9288 - val_loss: 0.2667 - val_accuracy: 0.9282\n",
      "Epoch 64/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2551 - accuracy: 0.9290 - val_loss: 0.2673 - val_accuracy: 0.9277\n",
      "Epoch 65/200\n",
      "375/375 [==============================] - 0s 925us/step - loss: 0.2547 - accuracy: 0.9291 - val_loss: 0.2689 - val_accuracy: 0.9267\n",
      "Epoch 66/200\n",
      "375/375 [==============================] - 0s 926us/step - loss: 0.2545 - accuracy: 0.9292 - val_loss: 0.2677 - val_accuracy: 0.9262\n",
      "Epoch 67/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2543 - accuracy: 0.9287 - val_loss: 0.2658 - val_accuracy: 0.9283\n",
      "Epoch 68/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2539 - accuracy: 0.9295 - val_loss: 0.2672 - val_accuracy: 0.9262\n",
      "Epoch 69/200\n",
      "375/375 [==============================] - 0s 925us/step - loss: 0.2538 - accuracy: 0.9296 - val_loss: 0.2666 - val_accuracy: 0.9274\n",
      "Epoch 70/200\n",
      "375/375 [==============================] - 0s 922us/step - loss: 0.2534 - accuracy: 0.9290 - val_loss: 0.2663 - val_accuracy: 0.9272\n",
      "Epoch 71/200\n",
      "375/375 [==============================] - 0s 934us/step - loss: 0.2533 - accuracy: 0.9297 - val_loss: 0.2660 - val_accuracy: 0.9275\n",
      "Epoch 72/200\n",
      "375/375 [==============================] - 0s 915us/step - loss: 0.2531 - accuracy: 0.9295 - val_loss: 0.2667 - val_accuracy: 0.9268\n",
      "Epoch 73/200\n",
      "375/375 [==============================] - 0s 923us/step - loss: 0.2527 - accuracy: 0.9292 - val_loss: 0.2667 - val_accuracy: 0.9285\n",
      "Epoch 74/200\n",
      "375/375 [==============================] - 0s 926us/step - loss: 0.2525 - accuracy: 0.9299 - val_loss: 0.2659 - val_accuracy: 0.9284\n",
      "Epoch 75/200\n",
      "375/375 [==============================] - 0s 938us/step - loss: 0.2524 - accuracy: 0.9301 - val_loss: 0.2672 - val_accuracy: 0.9267\n",
      "Epoch 76/200\n",
      "375/375 [==============================] - 0s 935us/step - loss: 0.2520 - accuracy: 0.9296 - val_loss: 0.2678 - val_accuracy: 0.9267\n",
      "Epoch 77/200\n",
      "375/375 [==============================] - 0s 930us/step - loss: 0.2519 - accuracy: 0.9296 - val_loss: 0.2661 - val_accuracy: 0.9281\n",
      "Epoch 78/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2517 - accuracy: 0.9295 - val_loss: 0.2665 - val_accuracy: 0.9278\n",
      "Epoch 79/200\n",
      "375/375 [==============================] - 0s 923us/step - loss: 0.2514 - accuracy: 0.9300 - val_loss: 0.2662 - val_accuracy: 0.9277\n",
      "Epoch 80/200\n",
      "375/375 [==============================] - 0s 944us/step - loss: 0.2512 - accuracy: 0.9291 - val_loss: 0.2656 - val_accuracy: 0.9281\n",
      "Epoch 81/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2510 - accuracy: 0.9300 - val_loss: 0.2663 - val_accuracy: 0.9277\n",
      "Epoch 82/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2509 - accuracy: 0.9300 - val_loss: 0.2672 - val_accuracy: 0.9262\n",
      "Epoch 83/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2507 - accuracy: 0.9300 - val_loss: 0.2666 - val_accuracy: 0.9283\n",
      "Epoch 84/200\n",
      "375/375 [==============================] - 0s 929us/step - loss: 0.2504 - accuracy: 0.9301 - val_loss: 0.2656 - val_accuracy: 0.9285\n",
      "Epoch 85/200\n",
      "375/375 [==============================] - 0s 925us/step - loss: 0.2502 - accuracy: 0.9305 - val_loss: 0.2667 - val_accuracy: 0.9290\n",
      "Epoch 86/200\n",
      "375/375 [==============================] - 0s 936us/step - loss: 0.2499 - accuracy: 0.9310 - val_loss: 0.2663 - val_accuracy: 0.9284\n",
      "Epoch 87/200\n",
      "375/375 [==============================] - 0s 923us/step - loss: 0.2497 - accuracy: 0.9306 - val_loss: 0.2661 - val_accuracy: 0.9277\n",
      "Epoch 88/200\n",
      "375/375 [==============================] - 0s 926us/step - loss: 0.2498 - accuracy: 0.9305 - val_loss: 0.2660 - val_accuracy: 0.9277\n",
      "Epoch 89/200\n",
      "375/375 [==============================] - 0s 952us/step - loss: 0.2495 - accuracy: 0.9307 - val_loss: 0.2673 - val_accuracy: 0.9275\n",
      "Epoch 90/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2493 - accuracy: 0.9305 - val_loss: 0.2665 - val_accuracy: 0.9283\n",
      "Epoch 91/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2491 - accuracy: 0.9308 - val_loss: 0.2670 - val_accuracy: 0.9277\n",
      "Epoch 92/200\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.9309 - val_loss: 0.2664 - val_accuracy: 0.9285\n",
      "Epoch 93/200\n",
      "375/375 [==============================] - 0s 998us/step - loss: 0.2488 - accuracy: 0.9299 - val_loss: 0.2666 - val_accuracy: 0.9286\n",
      "Epoch 94/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2484 - accuracy: 0.9307 - val_loss: 0.2669 - val_accuracy: 0.9279\n",
      "Epoch 95/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2483 - accuracy: 0.9306 - val_loss: 0.2671 - val_accuracy: 0.9275\n",
      "Epoch 96/200\n",
      "375/375 [==============================] - 0s 926us/step - loss: 0.2482 - accuracy: 0.9311 - val_loss: 0.2668 - val_accuracy: 0.9283\n",
      "Epoch 97/200\n",
      "375/375 [==============================] - 0s 930us/step - loss: 0.2481 - accuracy: 0.9311 - val_loss: 0.2661 - val_accuracy: 0.9282\n",
      "Epoch 98/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2479 - accuracy: 0.9309 - val_loss: 0.2658 - val_accuracy: 0.9292\n",
      "Epoch 99/200\n",
      "375/375 [==============================] - 0s 937us/step - loss: 0.2480 - accuracy: 0.9312 - val_loss: 0.2667 - val_accuracy: 0.9288\n",
      "Epoch 100/200\n",
      "375/375 [==============================] - 0s 924us/step - loss: 0.2476 - accuracy: 0.9311 - val_loss: 0.2667 - val_accuracy: 0.9282\n",
      "Epoch 101/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2473 - accuracy: 0.9311 - val_loss: 0.2674 - val_accuracy: 0.9277\n",
      "Epoch 102/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2473 - accuracy: 0.9310 - val_loss: 0.2670 - val_accuracy: 0.9290\n",
      "Epoch 103/200\n",
      "375/375 [==============================] - 0s 942us/step - loss: 0.2472 - accuracy: 0.9310 - val_loss: 0.2671 - val_accuracy: 0.9291\n",
      "Epoch 104/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2469 - accuracy: 0.9312 - val_loss: 0.2660 - val_accuracy: 0.9283\n",
      "Epoch 105/200\n",
      "375/375 [==============================] - 0s 918us/step - loss: 0.2468 - accuracy: 0.9311 - val_loss: 0.2656 - val_accuracy: 0.9287\n",
      "Epoch 106/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2467 - accuracy: 0.9307 - val_loss: 0.2666 - val_accuracy: 0.9282\n",
      "Epoch 107/200\n",
      "375/375 [==============================] - 0s 919us/step - loss: 0.2465 - accuracy: 0.9316 - val_loss: 0.2665 - val_accuracy: 0.9281\n",
      "Epoch 108/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2465 - accuracy: 0.9310 - val_loss: 0.2664 - val_accuracy: 0.9276\n",
      "Epoch 109/200\n",
      "375/375 [==============================] - 0s 921us/step - loss: 0.2461 - accuracy: 0.9314 - val_loss: 0.2663 - val_accuracy: 0.9288\n",
      "Epoch 110/200\n",
      "375/375 [==============================] - 0s 926us/step - loss: 0.2459 - accuracy: 0.9308 - val_loss: 0.2665 - val_accuracy: 0.9285\n",
      "Epoch 111/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2460 - accuracy: 0.9312 - val_loss: 0.2661 - val_accuracy: 0.9289\n",
      "Epoch 112/200\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.9310 - val_loss: 0.2666 - val_accuracy: 0.9277\n",
      "Epoch 113/200\n",
      "375/375 [==============================] - 0s 919us/step - loss: 0.2454 - accuracy: 0.9318 - val_loss: 0.2688 - val_accuracy: 0.9268\n",
      "Epoch 114/200\n",
      "375/375 [==============================] - 0s 929us/step - loss: 0.2453 - accuracy: 0.9315 - val_loss: 0.2682 - val_accuracy: 0.9283\n",
      "Epoch 115/200\n",
      "375/375 [==============================] - 0s 924us/step - loss: 0.2454 - accuracy: 0.9315 - val_loss: 0.2663 - val_accuracy: 0.9274\n",
      "Epoch 116/200\n",
      "375/375 [==============================] - 0s 939us/step - loss: 0.2452 - accuracy: 0.9317 - val_loss: 0.2670 - val_accuracy: 0.9282\n",
      "Epoch 117/200\n",
      "375/375 [==============================] - 0s 949us/step - loss: 0.2452 - accuracy: 0.9315 - val_loss: 0.2660 - val_accuracy: 0.9279\n",
      "Epoch 118/200\n",
      "375/375 [==============================] - 0s 961us/step - loss: 0.2449 - accuracy: 0.9316 - val_loss: 0.2666 - val_accuracy: 0.9291\n",
      "Epoch 119/200\n",
      "375/375 [==============================] - 0s 925us/step - loss: 0.2449 - accuracy: 0.9318 - val_loss: 0.2663 - val_accuracy: 0.9290\n",
      "Epoch 120/200\n",
      "375/375 [==============================] - 0s 940us/step - loss: 0.2448 - accuracy: 0.9319 - val_loss: 0.2661 - val_accuracy: 0.9278\n",
      "Epoch 121/200\n",
      "375/375 [==============================] - 0s 913us/step - loss: 0.2444 - accuracy: 0.9319 - val_loss: 0.2666 - val_accuracy: 0.9284\n",
      "Epoch 122/200\n",
      "375/375 [==============================] - 0s 929us/step - loss: 0.2443 - accuracy: 0.9314 - val_loss: 0.2676 - val_accuracy: 0.9272\n",
      "Epoch 123/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2442 - accuracy: 0.9318 - val_loss: 0.2663 - val_accuracy: 0.9287\n",
      "Epoch 124/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2443 - accuracy: 0.9317 - val_loss: 0.2661 - val_accuracy: 0.9287\n",
      "Epoch 125/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2442 - accuracy: 0.9323 - val_loss: 0.2665 - val_accuracy: 0.9291\n",
      "Epoch 126/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2438 - accuracy: 0.9321 - val_loss: 0.2669 - val_accuracy: 0.9290\n",
      "Epoch 127/200\n",
      "375/375 [==============================] - 0s 931us/step - loss: 0.2438 - accuracy: 0.9318 - val_loss: 0.2664 - val_accuracy: 0.9283\n",
      "Epoch 128/200\n",
      "375/375 [==============================] - 0s 930us/step - loss: 0.2436 - accuracy: 0.9322 - val_loss: 0.2671 - val_accuracy: 0.9283\n",
      "Epoch 129/200\n",
      "375/375 [==============================] - 0s 923us/step - loss: 0.2435 - accuracy: 0.9322 - val_loss: 0.2666 - val_accuracy: 0.9292\n",
      "Epoch 130/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2435 - accuracy: 0.9321 - val_loss: 0.2679 - val_accuracy: 0.9281\n",
      "Epoch 131/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2434 - accuracy: 0.9323 - val_loss: 0.2664 - val_accuracy: 0.9283\n",
      "Epoch 132/200\n",
      "375/375 [==============================] - 0s 919us/step - loss: 0.2432 - accuracy: 0.9325 - val_loss: 0.2664 - val_accuracy: 0.9283\n",
      "Epoch 133/200\n",
      "375/375 [==============================] - 0s 926us/step - loss: 0.2430 - accuracy: 0.9319 - val_loss: 0.2663 - val_accuracy: 0.9286\n",
      "Epoch 134/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2430 - accuracy: 0.9327 - val_loss: 0.2664 - val_accuracy: 0.9284\n",
      "Epoch 135/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2430 - accuracy: 0.9324 - val_loss: 0.2676 - val_accuracy: 0.9273\n",
      "Epoch 136/200\n",
      "375/375 [==============================] - 0s 924us/step - loss: 0.2427 - accuracy: 0.9320 - val_loss: 0.2671 - val_accuracy: 0.9281\n",
      "Epoch 137/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2426 - accuracy: 0.9325 - val_loss: 0.2669 - val_accuracy: 0.9282\n",
      "Epoch 138/200\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9325 - val_loss: 0.2677 - val_accuracy: 0.9283\n",
      "Epoch 139/200\n",
      "375/375 [==============================] - 0s 989us/step - loss: 0.2425 - accuracy: 0.9326 - val_loss: 0.2663 - val_accuracy: 0.9299\n",
      "Epoch 140/200\n",
      "375/375 [==============================] - 0s 912us/step - loss: 0.2422 - accuracy: 0.9323 - val_loss: 0.2672 - val_accuracy: 0.9289\n",
      "Epoch 141/200\n",
      "375/375 [==============================] - 0s 921us/step - loss: 0.2423 - accuracy: 0.9319 - val_loss: 0.2668 - val_accuracy: 0.9284\n",
      "Epoch 142/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2419 - accuracy: 0.9327 - val_loss: 0.2671 - val_accuracy: 0.9288\n",
      "Epoch 143/200\n",
      "375/375 [==============================] - 0s 938us/step - loss: 0.2421 - accuracy: 0.9324 - val_loss: 0.2668 - val_accuracy: 0.9291\n",
      "Epoch 144/200\n",
      "375/375 [==============================] - 0s 936us/step - loss: 0.2421 - accuracy: 0.9327 - val_loss: 0.2672 - val_accuracy: 0.9281\n",
      "Epoch 145/200\n",
      "375/375 [==============================] - 0s 914us/step - loss: 0.2416 - accuracy: 0.9326 - val_loss: 0.2678 - val_accuracy: 0.9284\n",
      "Epoch 146/200\n",
      "375/375 [==============================] - 0s 925us/step - loss: 0.2416 - accuracy: 0.9327 - val_loss: 0.2678 - val_accuracy: 0.9274\n",
      "Epoch 147/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2417 - accuracy: 0.9328 - val_loss: 0.2671 - val_accuracy: 0.9286\n",
      "Epoch 148/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2416 - accuracy: 0.9326 - val_loss: 0.2671 - val_accuracy: 0.9287\n",
      "Epoch 149/200\n",
      "375/375 [==============================] - 0s 924us/step - loss: 0.2414 - accuracy: 0.9329 - val_loss: 0.2670 - val_accuracy: 0.9286\n",
      "Epoch 150/200\n",
      "375/375 [==============================] - 0s 922us/step - loss: 0.2412 - accuracy: 0.9325 - val_loss: 0.2680 - val_accuracy: 0.9274\n",
      "Epoch 151/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2413 - accuracy: 0.9327 - val_loss: 0.2669 - val_accuracy: 0.9283\n",
      "Epoch 152/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2412 - accuracy: 0.9329 - val_loss: 0.2666 - val_accuracy: 0.9289\n",
      "Epoch 153/200\n",
      "375/375 [==============================] - 0s 925us/step - loss: 0.2409 - accuracy: 0.9330 - val_loss: 0.2681 - val_accuracy: 0.9280\n",
      "Epoch 154/200\n",
      "375/375 [==============================] - 0s 936us/step - loss: 0.2408 - accuracy: 0.9330 - val_loss: 0.2666 - val_accuracy: 0.9290\n",
      "Epoch 155/200\n",
      "375/375 [==============================] - 0s 921us/step - loss: 0.2409 - accuracy: 0.9326 - val_loss: 0.2674 - val_accuracy: 0.9279\n",
      "Epoch 156/200\n",
      "375/375 [==============================] - 0s 941us/step - loss: 0.2407 - accuracy: 0.9329 - val_loss: 0.2680 - val_accuracy: 0.9273\n",
      "Epoch 157/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2407 - accuracy: 0.9324 - val_loss: 0.2668 - val_accuracy: 0.9287\n",
      "Epoch 158/200\n",
      "375/375 [==============================] - 0s 916us/step - loss: 0.2405 - accuracy: 0.9331 - val_loss: 0.2668 - val_accuracy: 0.9287\n",
      "Epoch 159/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2403 - accuracy: 0.9333 - val_loss: 0.2669 - val_accuracy: 0.9286\n",
      "Epoch 160/200\n",
      "375/375 [==============================] - 0s 928us/step - loss: 0.2404 - accuracy: 0.9336 - val_loss: 0.2671 - val_accuracy: 0.9277\n",
      "Epoch 161/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2403 - accuracy: 0.9332 - val_loss: 0.2672 - val_accuracy: 0.9289\n",
      "Epoch 162/200\n",
      "375/375 [==============================] - 0s 919us/step - loss: 0.2402 - accuracy: 0.9331 - val_loss: 0.2676 - val_accuracy: 0.9280\n",
      "Epoch 163/200\n",
      "375/375 [==============================] - 0s 921us/step - loss: 0.2399 - accuracy: 0.9334 - val_loss: 0.2675 - val_accuracy: 0.9287\n",
      "Epoch 164/200\n",
      "375/375 [==============================] - 0s 923us/step - loss: 0.2401 - accuracy: 0.9331 - val_loss: 0.2670 - val_accuracy: 0.9289\n",
      "Epoch 165/200\n",
      "375/375 [==============================] - 0s 947us/step - loss: 0.2398 - accuracy: 0.9335 - val_loss: 0.2673 - val_accuracy: 0.9285\n",
      "Epoch 166/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2398 - accuracy: 0.9331 - val_loss: 0.2677 - val_accuracy: 0.9282\n",
      "Epoch 167/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2397 - accuracy: 0.9337 - val_loss: 0.2680 - val_accuracy: 0.9293\n",
      "Epoch 168/200\n",
      "375/375 [==============================] - 0s 918us/step - loss: 0.2396 - accuracy: 0.9340 - val_loss: 0.2673 - val_accuracy: 0.9287\n",
      "Epoch 169/200\n",
      "375/375 [==============================] - 0s 915us/step - loss: 0.2396 - accuracy: 0.9332 - val_loss: 0.2676 - val_accuracy: 0.9288\n",
      "Epoch 170/200\n",
      "375/375 [==============================] - 0s 915us/step - loss: 0.2395 - accuracy: 0.9332 - val_loss: 0.2672 - val_accuracy: 0.9286\n",
      "Epoch 171/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2394 - accuracy: 0.9336 - val_loss: 0.2679 - val_accuracy: 0.9278\n",
      "Epoch 172/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2392 - accuracy: 0.9336 - val_loss: 0.2677 - val_accuracy: 0.9285\n",
      "Epoch 173/200\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.9334 - val_loss: 0.2678 - val_accuracy: 0.9284\n",
      "Epoch 174/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2390 - accuracy: 0.9331 - val_loss: 0.2681 - val_accuracy: 0.9292\n",
      "Epoch 175/200\n",
      "375/375 [==============================] - 0s 946us/step - loss: 0.2390 - accuracy: 0.9333 - val_loss: 0.2674 - val_accuracy: 0.9290\n",
      "Epoch 176/200\n",
      "375/375 [==============================] - 0s 925us/step - loss: 0.2389 - accuracy: 0.9341 - val_loss: 0.2675 - val_accuracy: 0.9291\n",
      "Epoch 177/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2389 - accuracy: 0.9333 - val_loss: 0.2673 - val_accuracy: 0.9283\n",
      "Epoch 178/200\n",
      "375/375 [==============================] - 0s 955us/step - loss: 0.2388 - accuracy: 0.9336 - val_loss: 0.2678 - val_accuracy: 0.9287\n",
      "Epoch 179/200\n",
      "375/375 [==============================] - 0s 947us/step - loss: 0.2387 - accuracy: 0.9335 - val_loss: 0.2682 - val_accuracy: 0.9287\n",
      "Epoch 180/200\n",
      "375/375 [==============================] - 0s 944us/step - loss: 0.2386 - accuracy: 0.9337 - val_loss: 0.2686 - val_accuracy: 0.9272\n",
      "Epoch 181/200\n",
      "375/375 [==============================] - 0s 934us/step - loss: 0.2388 - accuracy: 0.9335 - val_loss: 0.2677 - val_accuracy: 0.9287\n",
      "Epoch 182/200\n",
      "375/375 [==============================] - 0s 941us/step - loss: 0.2384 - accuracy: 0.9336 - val_loss: 0.2678 - val_accuracy: 0.9288\n",
      "Epoch 183/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2383 - accuracy: 0.9341 - val_loss: 0.2684 - val_accuracy: 0.9271\n",
      "Epoch 184/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2384 - accuracy: 0.9336 - val_loss: 0.2679 - val_accuracy: 0.9291\n",
      "Epoch 185/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2383 - accuracy: 0.9335 - val_loss: 0.2679 - val_accuracy: 0.9285\n",
      "Epoch 186/200\n",
      "375/375 [==============================] - 0s 976us/step - loss: 0.2382 - accuracy: 0.9339 - val_loss: 0.2677 - val_accuracy: 0.9294\n",
      "Epoch 187/200\n",
      "375/375 [==============================] - 0s 930us/step - loss: 0.2382 - accuracy: 0.9341 - val_loss: 0.2679 - val_accuracy: 0.9290\n",
      "Epoch 188/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2381 - accuracy: 0.9341 - val_loss: 0.2686 - val_accuracy: 0.9281\n",
      "Epoch 189/200\n",
      "375/375 [==============================] - 0s 945us/step - loss: 0.2380 - accuracy: 0.9335 - val_loss: 0.2680 - val_accuracy: 0.9291\n",
      "Epoch 190/200\n",
      "375/375 [==============================] - 0s 938us/step - loss: 0.2379 - accuracy: 0.9340 - val_loss: 0.2680 - val_accuracy: 0.9282\n",
      "Epoch 191/200\n",
      "375/375 [==============================] - 0s 932us/step - loss: 0.2377 - accuracy: 0.9342 - val_loss: 0.2688 - val_accuracy: 0.9276\n",
      "Epoch 192/200\n",
      "375/375 [==============================] - 0s 927us/step - loss: 0.2377 - accuracy: 0.9337 - val_loss: 0.2676 - val_accuracy: 0.9293\n",
      "Epoch 193/200\n",
      "375/375 [==============================] - 0s 930us/step - loss: 0.2376 - accuracy: 0.9339 - val_loss: 0.2679 - val_accuracy: 0.9288\n",
      "Epoch 194/200\n",
      "375/375 [==============================] - 0s 944us/step - loss: 0.2373 - accuracy: 0.9341 - val_loss: 0.2687 - val_accuracy: 0.9277\n",
      "Epoch 195/200\n",
      "375/375 [==============================] - 0s 952us/step - loss: 0.2374 - accuracy: 0.9337 - val_loss: 0.2677 - val_accuracy: 0.9285\n",
      "Epoch 196/200\n",
      "375/375 [==============================] - 0s 917us/step - loss: 0.2373 - accuracy: 0.9337 - val_loss: 0.2688 - val_accuracy: 0.9279\n",
      "Epoch 197/200\n",
      "375/375 [==============================] - 0s 920us/step - loss: 0.2374 - accuracy: 0.9337 - val_loss: 0.2694 - val_accuracy: 0.9274\n",
      "Epoch 198/200\n",
      "375/375 [==============================] - 0s 933us/step - loss: 0.2373 - accuracy: 0.9340 - val_loss: 0.2686 - val_accuracy: 0.9283\n",
      "Epoch 199/200\n",
      "375/375 [==============================] - 0s 947us/step - loss: 0.2372 - accuracy: 0.9336 - val_loss: 0.2680 - val_accuracy: 0.9292\n",
      "Epoch 200/200\n",
      "375/375 [==============================] - 0s 946us/step - loss: 0.2371 - accuracy: 0.9341 - val_loss: 0.2686 - val_accuracy: 0.9282\n"
     ]
    }
   ],
   "source": [
    "#train the network\n",
    "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MpCg_YTMP17"
   },
   "source": [
    "**Looking at the results of the trained network**\n",
    "\n",
    "Let's evaluate the model to see how well it has learned ( or not) the MNIST problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZN9rro7KMP19",
    "outputId": "3197ae6b-a74d-470b-fb58-365f140fbb35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 607us/step - loss: 0.2687 - accuracy: 0.9261\n",
      "\n",
      "Test score/loss: 0.2686692178249359\n",
      "Test accuracy: 0.9261000156402588\n"
     ]
    }
   ],
   "source": [
    "#test the network using the generalisation test dataset\n",
    "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZuRJvfwMP2K"
   },
   "source": [
    "Training the Multi-Layer Perceptron\n",
    "=========\n",
    "**Defining the network: Multi-Layer Perceptron**\n",
    "\n",
    "We will now create a multi-layer perceptron with 784 input units, two hidden layers with 128 hidden units each, and an output layer with the 10 units.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoF0ib-SMP2N",
    "outputId": "379100ca-a8b9-4d58-d64f-272400783603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 20 # we need fewer epoch than before, as the multi-layer percetpron can learn faster.\n",
    "N_HIDDEN = 128\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Hidden layer 1 with 128 hidden units and ReLu activation function\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "# Hidden layer 2 with 128 hidden units and ReLu activation function\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output layer with 10 units and softmax activation\n",
    "model.add(Dense(N_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Summary of the whole model\n",
    "model.summary()\n",
    "\n",
    "# model compilation\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgYzi3hyMP2V"
   },
   "source": [
    "**Let's train the mulri-layer perceptron network**\n",
    "\n",
    "Let's now train (fit) the network with the above-defined batch size (128), and number of epochs (20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNa3cmoaMP2X",
    "outputId": "8d099967-8a6b-405b-f915-54aaabac2ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.8568 - val_loss: 0.2715 - val_accuracy: 0.9215\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2348 - accuracy: 0.9307 - val_loss: 0.1933 - val_accuracy: 0.9447\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9472 - val_loss: 0.1721 - val_accuracy: 0.9510\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1450 - accuracy: 0.9578 - val_loss: 0.1628 - val_accuracy: 0.9519\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.9637 - val_loss: 0.1281 - val_accuracy: 0.9614\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9692 - val_loss: 0.1164 - val_accuracy: 0.9672\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9736 - val_loss: 0.1186 - val_accuracy: 0.9657\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0782 - accuracy: 0.9773 - val_loss: 0.1032 - val_accuracy: 0.9695\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0699 - accuracy: 0.9796 - val_loss: 0.0991 - val_accuracy: 0.9712\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0621 - accuracy: 0.9817 - val_loss: 0.0986 - val_accuracy: 0.9712\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0553 - accuracy: 0.9839 - val_loss: 0.1041 - val_accuracy: 0.9699\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0496 - accuracy: 0.9859 - val_loss: 0.0950 - val_accuracy: 0.9730\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9873 - val_loss: 0.0910 - val_accuracy: 0.9741\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0393 - accuracy: 0.9893 - val_loss: 0.0893 - val_accuracy: 0.9737\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.0875 - val_accuracy: 0.9752\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.0876 - val_accuracy: 0.9752\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0286 - accuracy: 0.9925 - val_loss: 0.0882 - val_accuracy: 0.9752\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0888 - val_accuracy: 0.9745\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0238 - accuracy: 0.9943 - val_loss: 0.0894 - val_accuracy: 0.9758\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.0893 - val_accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "#train the network\n",
    "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV5v4LNjMP2e"
   },
   "source": [
    "**Looking at the results of the trained network**\n",
    "\n",
    "Let's explotre the results both for the score and accuracy values, as well as to visualise the plots of these values during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXpu8p9uMP2f",
    "outputId": "2c144fed-3cf7-41f8-cd07-a0dadc7e6c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 741us/step - loss: 0.0750 - accuracy: 0.9768\n",
      "\n",
      "Test score/loss: 0.0750323012471199\n",
      "Test accuracy: 0.9768000245094299\n"
     ]
    }
   ],
   "source": [
    "#test the network\n",
    "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "yYRZkVf6MP2t",
    "outputId": "be2efff1-d201-4f54-821b-1b8a69aba865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "MJ9YbKviMP2z",
    "outputId": "faa63473-4582-4a51-a9db-52d2e5f707e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV-aShF1MP24"
   },
   "source": [
    "**Adding weight droputs**\n",
    "\n",
    "An efficient way to reduce the number of parameters (weights) to be trained, as well as to increase generalisation capabilities, is to randomly remove (i.e. __dropout__) a certain proportion of the nodes at random in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GNrMiVoMP25",
    "outputId": "49309e1e-949f-4f64-83df-0a602190c0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import the dropout layer type\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Probability of weights dropout\n",
    "P_DROPOUT = 0.3\n",
    "\n",
    "# We can increse this parameter afterwards\n",
    "N_EPOCH = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(P_DROPOUT))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(P_DROPOUT))\n",
    "model.add(Dense(N_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model compilation\n",
    "model.summary()\n",
    "\n",
    "# model compilation\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBJJWwueMP2-"
   },
   "source": [
    "**Let's train the multi-layer perceptron network with DROPOUT**\n",
    "\n",
    "Let's now train (fit) the above dropout network with the above-defined batch size (128), and number of epochs (250)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xqa-9UHxMP3A",
    "outputId": "2298bead-2990-4b63-ff55-ed1d8c344922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6720 - accuracy: 0.7951 - val_loss: 0.2701 - val_accuracy: 0.9231\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3409 - accuracy: 0.8995 - val_loss: 0.2056 - val_accuracy: 0.9391\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2701 - accuracy: 0.9204 - val_loss: 0.1658 - val_accuracy: 0.9524\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2334 - accuracy: 0.9309 - val_loss: 0.1487 - val_accuracy: 0.9572\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2054 - accuracy: 0.9392 - val_loss: 0.1315 - val_accuracy: 0.9628\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9459 - val_loss: 0.1225 - val_accuracy: 0.9639\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.9483 - val_loss: 0.1123 - val_accuracy: 0.9667\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9518 - val_loss: 0.1102 - val_accuracy: 0.9671\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1494 - accuracy: 0.9551 - val_loss: 0.1034 - val_accuracy: 0.9707\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1398 - accuracy: 0.9589 - val_loss: 0.1001 - val_accuracy: 0.9703\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1341 - accuracy: 0.9597 - val_loss: 0.0969 - val_accuracy: 0.9718\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1277 - accuracy: 0.9611 - val_loss: 0.0921 - val_accuracy: 0.9738\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9637 - val_loss: 0.0911 - val_accuracy: 0.9732\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1149 - accuracy: 0.9654 - val_loss: 0.0911 - val_accuracy: 0.9734\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1098 - accuracy: 0.9664 - val_loss: 0.0873 - val_accuracy: 0.9742\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1054 - accuracy: 0.9679 - val_loss: 0.0865 - val_accuracy: 0.9751\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9694 - val_loss: 0.0860 - val_accuracy: 0.9755\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9696 - val_loss: 0.0848 - val_accuracy: 0.9760\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9707 - val_loss: 0.0823 - val_accuracy: 0.9755\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9715 - val_loss: 0.0839 - val_accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "#train the network\n",
    "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-z1NP88MP3I"
   },
   "source": [
    "**Looking at the results of the trained dropout network**\n",
    "\n",
    "Let's explore the effects of adding the weight dropout on the network performance.\n",
    "\n",
    "You can see that the dropout has further improved our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "K8qIacDmMP3N",
    "outputId": "596dcc3a-f5d8-461c-bbb7-0dedd3d99f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 713us/step - loss: 0.0811 - accuracy: 0.9739\n",
      "\n",
      "Test score: 0.08105381578207016\n",
      "Test accuracy: 0.9739000201225281\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4S0lEQVR4nO3deXxddZ3/8dc7e9OkzdJ9TVsKtCC0UAoI+INBloJQQGFAYBCXwigj+FOHyowO6iyMP1FRGCpoR5RdAalaZRNEZWsLKaULtrRJm65p0ux78vn9cU7S29u0uUlzc7N8no/Hfdyz3vM9p+n93O8uM8M555yLVVKiE+Ccc25g8cDhnHOuWzxwOOec6xYPHM4557rFA4dzzrlu8cDhnHOuWzxwONcFST+T9O8xHlsk6aPxTpNzieSBwznnXLd44HBuiJCUkug0uMHBA4cbFMIioq9KeldSraSfShor6feSqiW9KCk34vhLJa2VVCHpFUmzIvbNlfR2eN4TQEbUtT4mqTA89zVJJ8SYxoslvSOpStI2SXdG7T8z/LyKcP+nwu3DJN0tqVhSpaS/hNvOllTSyXP4aLh8p6RfSXpYUhXwKUnzJb0eXmOnpHslpUWcf5ykFySVS9ot6Q5J4yTVScqPOO5kSaWSUmO5dze4eOBwg8nHgfOAo4FLgN8DdwCjCP7Wvwgg6WjgMeA2YDSwHPiNpLTwS/TXwC+APOCX4ecSnnsSsBS4CcgHfgwsk5QeQ/pqgX8AcoCLgX+UdFn4uVPC9P4oTNMcoDA877vAycCHwzT9M9AW4zNZCPwqvOYjQCvwJYJncjpwLvD5MA3ZwIvAH4AJwFHAS2a2C3gFuCric68DHjez5hjT4QYRDxxuMPmRme02s+3An4E3zewdM2sEngHmhsf9PfA7M3sh/OL7LjCM4Iv5NCAV+IGZNZvZr4AVEdf4HPBjM3vTzFrN7CGgMTzvsMzsFTNbY2ZtZvYuQfD6P+Hua4EXzeyx8LplZlYoKQn4NHCrmW0Pr/laeE+xeN3Mfh1es97MVpnZG2bWYmZFBIGvPQ0fA3aZ2d1m1mBm1Wb2ZrjvIYJggaRk4BqC4OqGIA8cbjDZHbFc38l6Vrg8AShu32FmbcA2YGK4b7sdOPpnccTyVODLYVFPhaQKYHJ43mFJOlXSy2ERTyVwM8Evf8LP+KCT00YRFJV1ti8W26LScLSk30raFRZf/WcMaQB4FpgtaTpBrq7SzN7qYZrcAOeBww1FOwgCAACSRPCluR3YCUwMt7WbErG8DfgPM8uJeGWa2WMxXPdRYBkw2cxGAkuA9utsA2Z0cs5eoOEQ+2qBzIj7SCYo5ooUPfz1/cAGYKaZjSAoyusqDZhZA/AkQc7oejy3MaR54HBD0ZPAxZLODSt3v0xQ3PQa8DrQAnxRUoqkK4D5Eec+CNwc5h4kaXhY6Z0dw3WzgXIza5A0H/hkxL5HgI9Kuiq8br6kOWFuaCnwPUkTJCVLOj2sU/kbkBFePxX4V6CrupZsoAqokXQs8I8R+34LjJN0m6R0SdmSTo3Y/3PgU8ClwMMx3K8bpDxwuCHHzN4nKK//EcEv+kuAS8ysycyagCsIviD3EdSHPB1x7kqCeo57w/2bwmNj8XngW5KqgW8QBLD2z90KXEQQxMoJKsZPDHd/BVhDUNdSDvw3kGRmleFn/oQgt1QLHNDKqhNfIQhY1QRB8ImINFQTFENdAuwCNgLnROz/K0Gl/Nth/YgbouQTOTnnYiXpj8CjZvaTRKfFJY4HDudcTCSdArxAUEdTnej0uMTxoirnXJckPUTQx+M2DxrOcxzOOee6xXMczjnnumVIDHo2atQoKygoSHQynHNuQFm1atVeM4vuGzQ0AkdBQQErV65MdDKcc25AkVTc2XYvqnLOOdctHjicc851iwcO55xz3TIk6jg609zcTElJCQ0NDYlOSlxlZGQwadIkUlN9vh3nXO8YsoGjpKSE7OxsCgoKOHAg1MHDzCgrK6OkpIRp06YlOjnOuUFiyBZVNTQ0kJ+fP2iDBoAk8vPzB32uyjnXt+IaOCRdKOl9SZskLe5kf66kZxTME/2WpOPD7ceEczq3v6ok3Rbuu1PS9oh9Fx1B+np8bwPFULhH51zfiltRVTipzH0EwzSXACskLTOzdRGH3QEUmtnl4dwA9wHnhsNez4n4nO0EU3+2+76ZfTdeaXfOuQ5m0NIQvJoboKU+fG/fVn/w/pbGYHtrMySnQuowSEmHlGGQmhG8p6SH2zM62R+++ukPv3jWccwHNpnZZgBJjwMLgcjAMRv4LwAz2yCpQNJYM4uc8vNc4AMz67QjykBVUVHBo48+yuc///lunXfRRRfx6KOPkpOTE5+EOTeQtLZAYxU0VEBDZSevquALvbUp+DJvaYTWxqjlpqhtTWEgaN+ewKLe5HRISoGkZFBS+B61nJQUvidHvEfsv/AumHxKryYrnoFjIgfOd1wCnBp1zGqCSXP+Es6INhWYxIFzRV8NRE/LeYukfwBWAl82s33RF5e0CFgEMGXKlOjdCVdRUcH//M//HBQ4WltbSU5OPuR5y5cvj3fS3GDRXA81e4Jfs2nDg1+zSf2kWrOtDZprobEGmmqgsTp8j16vDr78Ow0KldAUw0C9KRnBF3BKWvgevpLTwl/2aZCeHbE96pj2XEFKxv7cQmSu4HD7k9P2B6JYcyvR+60N2lrBWve/W1vwDCO3dbxHbU869PdJT8UzcHSWx4oeivcu4B5JhQQznL1DMG1n8AFSGsE0lV+LOOd+4NvhZ30buBv49EEXMnsAeABg3rx5/W4I4MWLF/PBBx8wZ84cUlNTycrKYvz48RQWFrJu3Touu+wytm3bRkNDA7feeiuLFi0C9g+fUlNTw4IFCzjzzDN57bXXmDhxIs8++yzDhg1L8J25PmMG9fugfAvs23Lwe/XOg89JHQ5pmUEgScuC1PbliFdqZrAvbXjwpdjWCm3N0NYS/MJva381B/tamyO2Rbxam4NXZ4GhqZaDvw46I8gYeeArbxpk5By8vbNXWlbig2V7EMoYmdh09KJ4Bo4SYHLE+iRgR+QBZlYF3AigoBZ3S/hqt4BgmsrdEed0LEt6kGCe5CPyzd+sZd2OqiP9mAPMnjCCf7vkuEPuv+uuu3jvvfcoLCzklVde4eKLL+a9997raDa7dOlS8vLyqK+v55RTTuHjH/84+fn5B3zGxo0beeyxx3jwwQe56qqreOqpp7juuut69T5cgrW1QtX2QwSHYmisPPD4rHHBF+v0c4L37PFBcUtT7cGv5rr9X+I1e4Ll5rr9+w5HyUERSnJq8Is2KQWSUvcXqySn7t+flgXDRwfpScsKft2nZUF6+3J2sNy+LXI9NTPxX/zuIPEMHCuAmZKmEVRuX00w13EHSTlAXTjP82eBV8Ng0u4aooqpJI03s/afUpcD78Un+X1r/vz5B/S1+OEPf8gzzwTtAbZt28bGjRsPChzTpk1jzpw5AJx88skUFRX1VXJdb2ishqqdQc6gelf4HrVetTP4Zd8uKRVypgRfwpPnQ+60YDl3GuQWBLmJ3tDWFgSP5voDA0H7q59W2g4VjS2t1DS0UNPYQnVDC7WNwXL7ek1jsK26oYXrTpvKUWOyevX6cQscZtYi6RbgOSAZWGpmayXdHO5fAswCfi6plaDS/DPt50vKJGiRdVPUR39H0hyCfG5RJ/u77XA5g74yfPjwjuVXXnmFF198kddff53MzEzOPvvsTvtipKendywnJydTX1/fJ2kd9JrqoGQFFL8GpevDX85pwZdnclrw5d2+HLk9uZPt1gbVuzsJDruCX/jR0rIhe1zwmnJ6kGPILdgfHEZOikuZ9UGSksIcQe9+4bj9GltaqahrZl9dE+W1TR3L+2qb2BcuV9Q1U9PQQnVjCzWNzdQ2BgGjqbWty8+XICs9hXNnjRk4gQPAzJYDy6O2LYlYfh2YeYhz64D8TrZf38vJTIjs7Gyqqzuv2KusrCQ3N5fMzEw2bNjAG2+80cepG2Iaq2Hbm1D0Vyj+K2x/O/iVryTImx4c09oUltk3BeX8rU3By1pju0ZyehgQxsO4D8HM8/evZ4+D7AmQPTYounEJ1dDcyu6qBnZVNrC3pomWtjbazGhrg1YzzIzWNoJtZrS1Ga1GuN1oMzq2N7cZlXX7A0EQGJqpqGuitunQfzuZacnkZqaRk5lKdkYKE3OGkZ2RTVZ6CsPTU8jOSCErPXxFLWeH78NSk+PWj2vIDjmSaPn5+Zxxxhkcf/zxDBs2jLFjx3bsu/DCC1myZAknnHACxxxzDKeddloCUzoI1e+DrW9A0V+CXMXO1WHrkxSYMBdO/wJMPQOmnNp1hWZ75XBrU1gh3HRgkAHIGgvDcr14J8Fa24yymkZ2hUFhd3UjuysbgiBRFbzvrmqksr656w/rhhEZKeQOTyM3M43RWekcPSY7XE8lJzONvOFBgMiNWE5P6YNc5REYEnOOz5s3z6Inclq/fj2zZs1KUIr61lC6107V7g1yEsWvBbmK3e8BFhQnTToFpn44CBST5wctidyAYmbsq2sOv/gb2FPdyJ4wCOyOCAilNY20th34fZecJEZnpTN2RDpjR2QwdkQG40ZmhMvpjM5OJzU5iSSJZAkpOCdJIimJju0HrCeFx3VsH7g/GCStMrN50ds9x+H6p9Zm2Pu3oPVQpx24wrbxh+zAFXbcqtkDe98PPjNlWBAczrkjCBYT5wXt7V2/1NZmVNY3s6e6sSMg7K5q2B8UqhvYU9VIaXVjp2X+OZmpjMkOAsLRY7ODYDAyg7HZ6YwbmcG4ERnkZ6WTPIC/2BPFA4dLvIaqIBewaw3sejd437N+f1HPoSgpqrNW2MmrveNVSnpQR3Hi1VBwJoyfE+x3fcbMqG9upbK+mYq65o73qvpmKuqbDtje/mpfr2poprMCkREZKYwJcwSnTsvrWB47IqMjUIzOTicjtX8X9wxkHjhc3zEL+iTsWnNgkNhXtP+YzHwYdwKcenPwPuqooC1/ZI/e9h6/yf7nm2h1TS3sqGhgR0V9x6ukYzmoO2hqOXQLoOQkMXJYascrNzONaaOGM3JYKjnDUhmZmdYRDMaOSGdMdgbD0jwgJJr/z3O9q7UlqHyu2wt1ZVBZcmCQqI8YHSZvRpALmHt9ECTGfShoYeSVyP2CmbG3pontYSDYvq++Y3lHZRAYymsPzBUmCcaOyGBizjDmTM5h3MgMcjPTgkCQmXpAkMjJTCUrPcVHcB6APHC4w2usDiqX68qDQNAeEGrD97ryA7c1VBz8GcnpMHY2zLokDBAnBOve9LTfqG9qZeOeatbvrGL9zmo27Kpiw65qKuoObGE0PC2ZibnDmJAzjBMm5TAxZxgTc4L1CTlBpXJqsvf0Huw8cLiD1ZXDe0/BOw/DzsLOj0lKDYqVho+CzLwgt5A56sBtmfnBEBj5R3mxUj9hZmyvqGfDziBIbNhVzfpdVRTtraW9wVFmWjLHjMtmwfHjOXpsFpNzMzuCxYgMzyE4DxwJ09Nh1QF+8IMfsGjRIjIze2l4CQj6I2x+JQgWG34XtFIa+yE4519hxIQgCGTmw/DwPX2EFyn1Yy2tbR3FTO/vCnIQ63dWsWFnNdWNHeOIMiUvk2PHZXPJCROYNT6bY8eNYEpe5oBuQurizwNHghxqWPVY/OAHP+C6667rncBRvhkKHw1eVduDUUdP/hTMvRbGn3jkn+96jZlR09jCnuqgCWppdWPH8p7qho5tpdWNlNc1HdAiKSs9hWPHZbNw7gRmjR/BseNGcMy4oCeyc93lfzUJEjms+nnnnceYMWN48sknaWxs5PLLL+eb3/wmtbW1XHXVVZSUlNDa2srXv/51du/ezY4dOzjnnHMYNWoUL7/8cvcv3lQL656Fdx6B4r8AgqPOhQv+A465KGi55HqdmdHY0nbQoHSRyzXhvupwe1V9C6U1+4NDQ/PBLZRSk4NObKNHZDApN5OTpuYG69npjBuRwTHjspmUO8yLmFyv8cAB8PvFQYuf3jTuQ7DgrkPujhxW/fnnn+dXv/oVb731FmbGpZdeyquvvkppaSkTJkzgd7/7HRCMYTVy5Ei+973v8fLLLzNq1KjY02MWjMf0zsOw9plggL286fB3X4cTr4GRE4/0jl1oR0U9r31QxusflLF2R2XHaKU1jS0H9VzujARZafvHJBqdnc7cKTmMyQ6CwejsoFlq8J7OyGGpHhRcn/LA0Q88//zzPP/888ydOxeAmpoaNm7cyFlnncVXvvIVbr/9dj72sY9x1llndf/DW5uCDnb3zoOyTcFEPsddBnOvC0Zf9S+cI7anuoHXPyjjjc1lvPZBGcVlwVwWecPTmDs5h5zMNLIzUhienhwEg3CgusiB6SLXh6Umex2D69c8cMBhcwZ9wcz42te+xk03HTxC/KpVq1i+fDlf+9rXOP/88/nGN77R9Qe2NgfNYuvDqTUbKoKJdM64LQga3gz2iOyrbeKNzWW8HgaKTXuC4dGzM1I4dVo+N5xewOkz8jlmbLYHADcoeeBIkMhh1S+44AK+/vWvc+2115KVlcX27dtJTU2lpaWFvLw8rrvuOrKysvjZz352wLkHFFW1NAUBoqEinJaToP9E1ljIToZP/6FP728wqWpo5q3N5R2BYv3OYK6xzLRkTinI48qTJ3H6jHyOmzDSxz1yQ4IHjgSJHFZ9wYIFfPKTn+T0008HICsri4cffphNmzbx1a9+laSkJFJTU7n//vsBWLRoEQsWLGD8uLG8/Jsng2DRPtVnSkbQ+zojJ1iWILmy80S4TpVWN7KquJyVRftYUVTOmu2VtBmkpyRx8tRcvnL+0Zw+I58TJuV4Zzc3JPmw6gNNc/3+YqiWcMa/1Mxg3oiMnE5Hex2w99oH2tqMTaU1rCzax8riclYV7+uoo0hLSWLOpBxOm5HP6dPzmTslxwfOc0OKD6s+UJntDxYNFcFw4RBUco+YGAQMbz4bs/qmVgq3VbAqDBKrivdR1RB0iMsfnsbJU3O59tQpnDw1j+Mnjuj3E+o4lwhxDRySLgTuIZhz/CdmdlfU/lxgKTADaAA+bWbvhfuKgGqgFWhpj3qS8oAngAKCOcevMrN9DEZ15cH81O3Di6dlwcjRQc4iOTWhSRso9lQ1sLJ4HyuL9rGquJy1O6poCZvEHjUmi4s+NJ6Tp+YyryCPgvxMb9bqXAziFjgkJQP3AecBJcAKScvMbF3EYXcAhWZ2uaRjw+PPjdh/jpntjfroxcBLZnaXpMXh+u09SaOZ9d8viprdULUjKIbKGhfkLHow3tNQKIpsZ2YUldWxYks5bxWVs6KovKPYKT0liRMn57DoI9OZV5DLSVNyycn0uTmc64l45jjmA5vMbDOApMeBhUBk4JgN/BeAmW2QVCBprJntPsznLgTODpcfAl6hB4EjIyODsrIy8vPz+1fwMAsCRu2eIGeROzWYsKhHH2WUlZWRkTE4Z7lrbTM27KrirS1BkFhRtI/S6qAoLzczlVMK8rju1KnMK8jluAkjSUvximznekM8A8dEYFvEeglwatQxq4ErgL9Img9MBSYBuwEDnpdkwI/N7IHwnLFmthPAzHZKGtOTxE2aNImSkhJKS0t7cnp8mEF9edCcNj0bMtJh9/tH9JEZGRlMmjSplxKYWI0trbxbUtkRKFYV7esYsG9izjDOmJHPKdPyOHVaHjNGZ/WvHwTODSLxDByd/a+NLje5C7hHUiGwBngHaB+68wwz2xEGhhckbTCzV2O+uLQIWAQwZcqUg/anpqYybdq0WD8u/prq4Jefgo3PwTn/Aqd9dUj36m6fRGjdzqqg6GlLOYUlFR2zyR01JouPnTiBU6flccq0PCbmDEtwip0bOuIZOEqAyRHrk4AdkQeYWRVwI4CCn4dbwhdmtiN83yPpGYKir1eB3ZLGh7mN8cCezi4e5lAegKA5bi/eV++rK4dH/x62r4SPfR/mfTrRKeozrW1Gyb46PiitYdOe/a8PSmuprA8mEUpOEsdPGME/nDaVU6blcUpBHnnDvX7CuUSJZ+BYAcyUNA3YDlwNfDLyAEk5QJ2ZNQGfBV41sypJw4EkM6sOl88HvhWetgy4gSC3cgPwbBzvIf4qt8PDVwTDm1/5EMy+NNEpiouG5la27K3dHxxKa/hgTw1b9tbSGDEn9aisNGaMzuJjJ4xnxugsjhmXzZzJOQz34b+d6zfi9r/RzFok3QI8R9Acd6mZrZV0c7h/CTAL+LmkVoJK88+Ep48FngnLqFOAR82sfcyMu4AnJX0G2ApcGa97iLvS9+EXV0BjFVz3NEzrwSCG/VRjSyvPFu7gD+/tYtOeGrbtq+uYH0KCSbnDOGp0FmfNHMVRY7KYMTqLo8ZkeUsn5waAIdtzPOFKVsIjnwimYL3uKRh/QqJT1CuqGpp59M2tLP3LFvZUN1KQn8lxE0d2BIajRmcxffRw74Ht3ADgPcf7k40vwpPXBwMQXv90MC/GALezsp7//WsRj765lZrGFs44Kp/vXnkiZ80c5a2bnBtkPHD0tXefhF//I4yZHeQ0snrUmrjfeH9XNQ+8upllq7fT2mZcfMIEbvrIdI6fODLRSXPOxYkHjr70+n3w3B1QcBZc/ShkjEh0inrEzHhzSzk//tMHvPx+KcNSk7n21Kl85sxpTM7rhXnQnXP9mgeOvmAGL94Jf/0BzLoUrniw01Fs+7vWNuO5tbv48Z8+YHVJJfnD0/i/5x3N9adNJdebxzo3ZHjgiLfWFvjNrVD4cNA/46LvQtLAqhhuaG7ll6tK+MmfN1NcVkdBfib/ftnxfOLkSV7J7dwQ5IEjnprq4Fc3wt/+AGd/Df7P7QOqN3hlXTM/e62Ih14vory2iRMn57D4wmM5/7hxPtOdc0OYB454aWmEx6+BzX+Ci++GUz6b6BTFrLm1jYffKOaelzZSUdfMuceOYdFHpjN/Wp63kHLOeeCIi7ZWeHoRbH4FFt4Hc69LdIpiYma8tH4P/7l8PZv31nLGUfn8y0WzmT1hYFbiO+fiwwNHbzOD5V+Fdb+G8749YILGuh1V/Mfydfx1UxnTRw/npzfM4++OHeM5DOfcQTxw9LZX7oKVP4UPfxHO+GKiU9OlPdUN3P3c33hy1TZGDkvlzktmc+1pU0lN9rkrnHOd88DRm958AP50F8y5Ds77VtfHJ1BDcys/+fNm/ueVD2hubePTZ0zji383k5GZPiWtc+7wPHD0ljW/gt//MxxzEVxyT79tPWVmLFu9g//+/QZ2VDZwwXFjWbxgFtNGDU900pxzA4QHjt6w6SV45maY+mH4xNIezQ3eF1YVl/Pt366ncFsFx00Ywd1XzeH0GfmJTpZzboDpn99wA0nJSnjiehh9LFzzGKT2v5notpXXcdcfNvC7d3cyJjud//eJE/j4SZNI8r4Yzrke8MBxJErfD4ZGzxodDFiY0b8G9qtpbOHeP25i6V+3kCT44rkzuekj031SJOfcEfFvkJ6qLIFfXB7Mp3H9M5A9NtEpOsA7W/dx6+OFbC2v44q5E/nqhccwfmT/yw055wYeDxw9UVsWBI3GavjU7/rVfBqtbcb9r2zi+y9uZNyIDH558+mcUpCX6GQ55wYRDxzd1VgDj14J+4qDnEY/mrlve0U9X3qikLe2lHPpiRP49mXHM3KYN691zvUuDxzd0dIUzNy34x34+4eh4IxEp6jDb9/dwR1Pr6G1zfjeVSdy+dyJ3uvbORcXce0eLOlCSe9L2iRpcSf7cyU9I+ldSW9JOj7cPlnSy5LWS1or6daIc+6UtF1SYfi6KJ730KGtDZ65CT74I1z6Izj24j65bFdqG1v46i9Xc8uj7zB9dBbLbz2LK06a5EHDORc3cctxSEoG7gPOA0qAFZKWmdm6iMPuAArN7HJJx4bHnwu0AF82s7clZQOrJL0Qce73zey78Ur7QcyCzn1rn4aPfrPfjD+1elsFtz7+DsXldfzT3x3FF8+d6UOFOOfiLp5FVfOBTWa2GUDS48BCIDJwzAb+C8DMNkgqkDTWzHYCO8Pt1ZLWAxOjzu07f/oOrHgQPvxPcOZtCUlCpNY248evfsD3nv8bY7LTefxzp3HqdO/I55zrG/H8eToR2BaxXhJui7QauAJA0nxgKjAp8gBJBcBc4M2IzbeExVtLJeV2dnFJiyStlLSytLS053ex4ifwyn/CnGuD0W4TbGdlPdf+5A2+84f3ueD4cfz+1o940HDO9al4Bo7OCtktav0uIFdSIfBPwDsExVTBB0hZwFPAbWZWFW6+H5gBzCHIldzd2cXN7AEzm2dm80aPHt2zO3jvafjdV+DoBXDJDxM+/tTv1+zkwh/8mXdLKvnOJ07g3mvm+qCEzrk+F8+iqhJgcsT6JGBH5AFhMLgRQEFt7pbwhaRUgqDxiJk9HXHO7vZlSQ8Cv41T+qGiGKacDlf+b0LHn6prauFbv1nH4yu2ccKkkdxz9VwflNA5lzDx/DZcAcyUNA3YDlwNfDLyAEk5QJ2ZNQGfBV41s6owiPwUWG9m34s6Z3xYBwJwOfBe3O7gzC/B6bdAcuJ+1b+3vZIvPvYOW8pq+cezZ/Cljx5NWopXgDvnEidugcPMWiTdAjwHJANLzWytpJvD/UuAWcDPJbUSVHx/Jjz9DOB6YE1YjAVwh5ktB74jaQ5BsVcRcFO87gFIaNBYtnoHX36ykPzh6Tzy2VP58IxRCUuLc861k1l0tcPgM2/ePFu5cmWik9EtxWW1LLjnz8weP4Kf3DCPnMy0RCfJOTfESFplZvOit3uZRz/U0trGl54oJCVJ/PCauR40nHP9ig850g/9zysf8PbWCn54zVwm5PiIts65/sVzHP3M6m0V3PPSRhbOmcClJ05IdHKcc+4gHjj6kbqmFr70RCFjs9P51sLjE50c55zrlBdV9SP/8bv1bCmr5dHPnubDoTvn+i3PcfQTf9ywm0fe3MrnzprO6TN8CBHnXP/lgaMf2FvTyD//6l2OHZfNl88/OtHJcc65w/KiqgQzMxY/tYaqhhYe+exppKckJzpJzjl3WJ7jSLDHV2zjxfW7+ecLjuGYcdmJTo5zznXJA0cCFe2t5du/XccZR+Xz6TOmJTo5zjkXEw8cCdLS2sZtYe/w7155IklJPtWrc25g8DqOBLn35U0UbqvgR9fMZfxI7x3unBs4PMeRAO9s3ceP/riJy+dO5BLvHe6cG2A8cPSx2sagd/i4ERl8c+FxiU6Oc851mxdV9bF//916isvreOxzpzEiw3uHO+cGHs9x9KEX1+3msbe2sugj0zltuvcOd84NTB44+khpdSO3P/Uus8aP4P+e573DnXMDV0yBQ9JTki6W5IGmB4Le4e9S3djCPVfP8d7hzrkBLdZAcD/wSWCjpLskHRvLSZIulPS+pE2SFneyP1fSM5LelfSWpOO7OldSnqQXJG0M33NjvIeEefStrby0YQ+LLzyWo8d673Dn3MAWU+AwsxfN7FrgJKAIeEHSa5JulNRpDa+kZOA+YAEwG7hG0uyow+4ACs3sBOAfgHtiOHcx8JKZzQReCtf7rc2lNfz7b9dz5lGj+NSHCxKdHOecO2IxFz1Jygc+BXwWeIfgS/4k4IVDnDIf2GRmm82sCXgcWBh1zGyCL3/MbANQIGlsF+cuBB4Klx8CLov1Hvpac2sbX3pyNWkpSd473Dk3aMRax/E08GcgE7jEzC41syfM7J+ArEOcNhHYFrFeEm6LtBq4IrzGfGAqMKmLc8ea2U6A8H3MIdK8SNJKSStLS0tjuc1e9/PXi1m9rYL/vPxDjBuZkZA0OOdcb4u1H8e9ZvbHznaY2bxDnNPZz2uLWr8LuEdSIbCGICfTEuO5h2VmDwAPAMybN69b5/aWt4v3UZCfycUnjE/E5Z1zLi5iLaqaJSmnfSWs1P58F+eUAJMj1icBOyIPMLMqM7vRzOYQ1HGMBrZ0ce5uSePDdIwH9sR4D32uqKyWglHDE50M55zrVbEGjs+ZWUX7ipntAz7XxTkrgJmSpklKA64GlkUeICkn3AdB3cmrZlbVxbnLgBvC5RuAZ2O8hz5lZhSX1VGQ74HDOTe4xFpUlSRJZmbQ0eop7XAnmFmLpFuA54BkYKmZrZV0c7h/CTAL+LmkVmAd8JnDnRt+9F3Ak5I+A2wFroz9dvtOWW0TNY0tTM3PTHRSnHOuV8UaOJ4j+LJeQlDXcDPwh65OMrPlwPKobUsill8HZsZ6bri9DDg3xnQnTHFZLYDnOJxzg06sgeN24CbgHwkqrp8HfhKvRA0GRXvrADzH4ZwbdGIKHGbWRtB7/P74JmfwKC6rJUkwKdcDh3NucIkpcEiaCfwXQYe9jg4JZjY9Tuka8IrK6piYO4y0FB/eyzk3uMT6rfa/BLmNFuAc4OfAL+KVqMGguKzW6zecc4NSrIFjmJm9BMjMis3sTuDv4pesga+orM7rN5xzg1KsleMN4ZDqG8Nmsts5xFAfDirqmqisb/Ych3NuUIo1x3EbwThVXwROBq5jfyc8F6WorL1FlQcO59zg02WOI+zsd5WZfRWoAW6Me6oGuP19OLyoyjk3+HSZ4zCzVuBkST4meIyK9tYhweQ8DxzOucEn1jqOd4BnJf0SqG3faGZPxyVVA1xxWS3jR2SQkepTxDrnBp9YA0ceUMaBLakM8MDRiaKyWq/fcM4NWrH2HPd6jW4oLqvj/OPGJjoZzjkXF7H2HP9fOplIycw+3espGuCqGpopq23yHIdzbtCKtajqtxHLGcDlRE3K5AJbw6a43qLKOTdYxVpU9VTkuqTHgBfjkqIBrtj7cDjnBrmejsA3E5jSmwkZLIrCPhw+3IhzbrCKtY6jmgPrOHYRzNHhohSX1TImO53MtFhLAZ1zbmCJtagqO94JGSx8cEPn3GAXU1GVpMsljYxYz5F0WQznXSjpfUmbJC3uZP9ISb+RtFrSWkk3htuPkVQY8aqSdFu4705J2yP2XRTrzfaFYu/D4Zwb5GKt4/g3M6tsXzGzCuDfDndCOMbVfcACggmgrpE0O+qwLwDrzOxE4GzgbklpZva+mc0xszkEgyrWAc9EnPf99v3h3OT9Ql1TC7urGr1FlXNuUIs1cHR2XFfFXPOBTWa22cyagMeBhVHHGJAdjoOVBZQTTBYV6VzgAzMrjjGtCbO13FtUOecGv1gDx0pJ35M0Q9J0Sd8HVnVxzkRgW8R6Sbgt0r3ALII+IWuAW8P5zSNdDTwWte0WSe9KWiopN8Z7iLuive19ODxwOOcGr1gDxz8BTcATwJNAPUEx0+F0NppudO/zC4BCYAIwB7hX0oiOD5DSgEuBX0accz8wIzx+J3B3pxeXFklaKWllaWlpF0ntHe3DqU/xoirn3CAWa6uqWuCgyu0ulACTI9YncXBv8xuBu8zMgE2StgDHAm+F+xcAb5vZ7oi0dCxLepADe7VHpvkB4AGAefPmHTRcSjwUldWRNzyNkcNS++JyzjmXELG2qnpBUk7Eeq6k57o4bQUwU9K0MOdwNbAs6pitBHUYSBoLHANsjth/DVHFVJLGR6xeDrwXyz30haBFlec2nHODW6y91EaFLakAMLN9kg4757iZtYTzkz8HJANLzWytpJvD/UuAbwM/k7SGoGjrdjPbCyApEzgPuCnqo78jaQ5BsVdRJ/sTprisjvnT8hKdDOeci6tYA0ebpClmthVAUgGdjJYbLWwquzxq25KI5R3A+Yc4tw7I72T79TGmuU81NLeyo7LecxzOuUEv1sDxL8BfJP0pXP8IsCg+SRqYSvbVYeYtqpxzg1+sleN/kDSPIFgUAs8StKxyofamuJ7jcM4NdrEOcvhZ4FaCllGFwGnA6xw4leyQ1j4qruc4nHODXaz9OG4FTgGKzewcYC7QN50jBojisjpGZKSQk+lNcZ1zg1usgaPBzBoAJKWb2QaCprMuVFRWS8Go4QSjpzjn3OAVa+V4SdiP49fAC5L24VPHHqC4rI4TJ+ckOhnOORd3sVaOXx4u3inpZWAk8Ie4pWqAaW5tY3tFPQvnTEh0UpxzLu66PU2dmf2p66OGlu376mltMx8V1zk3JPR0znEXYX+LKm+K65wb/Dxw9ILiMp+Hwzk3dHjg6AVFZbUMT0tmVFZaopPinHNx54GjFxSX1TEl35viOueGBg8cvaCorNbrN5xzQ4YHjiPU2mZsK6/z+g3n3JDhgeMI7aiop7nVPMfhnBsyPHAcIW9R5ZwbajxwHKGOPhyjPMfhnBsaPHAcoeKyWtJTkhibnZHopDjnXJ/wwHGEisrqmJqfSVKSN8V1zg0NcQ0cki6U9L6kTZIWd7J/pKTfSFotaa2kGyP2FUlaI6lQ0sqI7XmSXpC0MXzPjec9dKW4rNbrN5xzQ0rcAoekZOA+YAEwG7hG0uyow74ArDOzE4GzgbslRXa/PsfM5pjZvIhti4GXzGwm8FK4nhBtbUZxWZ23qHLODSnxzHHMBzaZ2WYzawIeBxZGHWNAtoIu11lAOdDSxecuBB4Klx8CLuu1FHfT7uoGGlvaPMfhnBtS4hk4JgLbItZLwm2R7gVmEUwKtQa41czawn0GPC9plaRFEeeMNbOdAOH7mM4uLmmRpJWSVpaWxmeW26K9QVNcn2fcOTeUxDNwdFZbbFHrFwCFwARgDnCvpBHhvjPM7CSCoq4vSPpIdy5uZg+Y2Twzmzd69OhuJTxWxWFT3KleVOWcG0LiGThKgMkR65M4eLrZG4GnLbAJ2AIcC2BmO8L3PcAzBEVfALsljQcI3/fE7Q66UFRWR2qymJAzLFFJcM65PhfPwLECmClpWljhfTWwLOqYrcC5AJLGAscAmyUNl5Qdbh8OnA+8F56zDLghXL4BeDaO93BYxWW1TM7LJNmb4jrnhpBuTx0bKzNrkXQL8ByQDCw1s7WSbg73LwG+DfxM0hqCoq3bzWyvpOnAM+Ew5SnAo2bWPsf5XcCTkj5DEHiujNc9dCVoUeX1G865oSVugQPAzJYDy6O2LYlY3kGQm4g+bzNw4iE+s4wwl5JIZkZxWS2nTs9LdFKcc65Pec/xHtpb00RtU6vnOJxzQ44Hjh7yFlXOuaHKA0cPFZV5Hw7n3NDkgaOHistqSU4SE3O9Ka5zbmjxwNFDRWV1TMwZRmqyP0Ln3NDi33o9FIyK6/UbzrmhxwNHD5gZW/bWev2Gc25I8sDRAxV1zVQ3tHiOwzk3JHng6IGOecY9x+GcG4I8cPRAcXtT3FGe43DODT0eOHqgqKwWCSbleuBwzg09Hjh6oLisjgkjh5GRmpzopDjnXJ/zwNEDRd4U1zk3hHng6IHisjqfZ9w5N2R54OimyvpmymubKPAch3NuiPLA0U1bwxZVnuNwzg1VHji6qaMPhzfFdc4NUR44umlreZDjmJLngcM5NzTFNXBIulDS+5I2SVrcyf6Rkn4jabWktZJuDLdPlvSypPXh9lsjzrlT0nZJheHronjeQ7SivbWMHZFOZlpcZ911zrl+K27ffpKSgfuA84ASYIWkZWa2LuKwLwDrzOwSSaOB9yU9ArQAXzaztyVlA6skvRBx7vfN7LvxSvvheIsq59xQF88cx3xgk5ltNrMm4HFgYdQxBmRLEpAFlAMtZrbTzN4GMLNqYD0wMY5pjVlRWa23qHLODWnxDBwTgW0R6yUc/OV/LzAL2AGsAW41s7bIAyQVAHOBNyM23yLpXUlLJeV2dnFJiyStlLSytLT0yO4kVNfUwp7qRs9xOOeGtHgGDnWyzaLWLwAKgQnAHOBeSSM6PkDKAp4CbjOzqnDz/cCM8PidwN2dXdzMHjCzeWY2b/To0T2/iwjFPs+4c87FNXCUAJMj1icR5Cwi3Qg8bYFNwBbgWABJqQRB4xEze7r9BDPbbWatYc7kQYIisT5RHDbF9eFGnHNDWTwDxwpgpqRpktKAq4FlUcdsBc4FkDQWOAbYHNZ5/BRYb2bfizxB0viI1cuB9+KU/oMUdXT+88DhnBu64taqysxaJN0CPAckA0vNbK2km8P9S4BvAz+TtIagaOt2M9sr6UzgemCNpMLwI+8ws+XAdyTNISj2KgJuitc9RCsuqyV/eBrZGal9dUnnnOt34toZIfyiXx61bUnE8g7g/E7O+wud15FgZtf3cjJjVrS3znMbzrkhz3uOd0NxWa1XjDvnhjwPHDFqaG5lR2WDN8V1zg15HjhitK3c5xl3zjnwwBGzIh9O3TnnAA8cMWvvw+HDjTjnhjoPHDEqKqtl5LBUcjLTEp0U55xLKA8cMSouq/PchnPO4YEjZkVltV6/4ZxzeOCISVNLG9v31XuOwznn8MARk+0V9bSZt6hyzjnwwBGTovYWVd6HwznnPHDEonhv+3DqnuNwzjkPHDEoKqsjKz2F/OHeFNc55zxwxKC4rJap+ZkE04Q459zQ5oEjBkEfDi+mcs458MDRpZbWNrbt83k4nHOunQeOLuysbKC51TzH4ZxzIQ8cXWhvius5DuecC8Q1cEi6UNL7kjZJWtzJ/pGSfiNptaS1km7s6lxJeZJekLQxfM+N5z34cOrOOXeguAUOScnAfcACYDZwjaTZUYd9AVhnZicCZwN3S0rr4tzFwEtmNhN4KVyPm+K9tWSkJjEmOz2el3HOuQEjnjmO+cAmM9tsZk3A48DCqGMMyFbQzjULKAdaujh3IfBQuPwQcFkc74Gisjqm5g0nKcmb4jrnHMQ3cEwEtkWsl4TbIt0LzAJ2AGuAW82srYtzx5rZToDwfUzvJ32/9j4czjnnAvEMHJ39RLeo9QuAQmACMAe4V9KIGM89/MWlRZJWSlpZWlranVM7tLUZxeV1FIzy+g3nnGsXz8BRAkyOWJ9EkLOIdCPwtAU2AVuAY7s4d7ek8QDh+57OLm5mD5jZPDObN3r06B7dwK6qBppa2jzH4ZxzEeIZOFYAMyVNk5QGXA0sizpmK3AugKSxwDHA5i7OXQbcEC7fADwbrxvoGBXXW1Q551yHlHh9sJm1SLoFeA5IBpaa2VpJN4f7lwDfBn4maQ1B8dTtZrYXoLNzw4++C3hS0mcIAs+V8bqH4o6muJ7jcM65dnELHABmthxYHrVtScTyDuD8WM8Nt5cR5lLiraislrTkJMaPHNYXl3POuQHBe44fxrT84Vw+dyLJ3hTXOec6xDXHMdBdPX8KV8+fkuhkOOdcv+I5Duecc93igcM551y3eOBwzjnXLR44nHPOdYsHDuecc93igcM551y3eOBwzjnXLR44nHPOdYvMujVa+YAkqRQo7uHpo4C9vZic3ubpOzKeviPj6Tty/TmNU83soOHFh0TgOBKSVprZvESn41A8fUfG03dkPH1HbiCkMZoXVTnnnOsWDxzOOee6xQNH1x5IdAK64Ok7Mp6+I+PpO3IDIY0H8DoO55xz3eI5Duecc93igcM551y3eOAISbpQ0vuSNkla3Ml+SfphuP9dSSf1YdomS3pZ0npJayXd2skxZ0uqlFQYvr7RV+kLr18kaU147ZWd7E/k8zsm4rkUSqqSdFvUMX36/CQtlbRH0nsR2/IkvSBpY/iee4hzD/u3Gsf0/T9JG8J/v2ck5Rzi3MP+LcQxfXdK2h7xb3jRIc5N1PN7IiJtRZIKD3Fu3J/fETOzIf8CkoEPgOlAGrAamB11zEXA7wEBpwFv9mH6xgMnhcvZwN86Sd/ZwG8T+AyLgFGH2Z+w59fJv/Uugo5NCXt+wEeAk4D3IrZ9B1gcLi8G/vsQ6T/s32oc03c+kBIu/3dn6YvlbyGO6bsT+EoM//4JeX5R++8GvpGo53ekL89xBOYDm8xss5k1AY8DC6OOWQj83AJvADmSxvdF4sxsp5m9HS5XA+uBiX1x7V6UsOcX5VzgAzPr6UgCvcLMXgXKozYvBB4Klx8CLuvk1Fj+VuOSPjN73sxawtU3gEm9fd1YHeL5xSJhz6+dJAFXAY/19nX7igeOwERgW8R6CQd/McdyTNxJKgDmAm92svt0Sasl/V7ScX2bMgx4XtIqSYs62d8vnh9wNYf+D5vI5wcw1sx2QvBjARjTyTH95Tl+miAH2Zmu/hbi6ZawKG3pIYr6+sPzOwvYbWYbD7E/kc8vJh44AupkW3Q75ViOiStJWcBTwG1mVhW1+22C4pcTgR8Bv+7LtAFnmNlJwALgC5I+ErW/Pzy/NOBS4Jed7E7084tVf3iO/wK0AI8c4pCu/hbi5X5gBjAH2ElQHBQt4c8PuIbD5zYS9fxi5oEjUAJMjlifBOzowTFxIymVIGg8YmZPR+83syozqwmXlwOpkkb1VfrMbEf4vgd4hqBIIFJCn19oAfC2me2O3pHo5xfa3V58F77v6eSYRP8d3gB8DLjWwgL5aDH8LcSFme02s1YzawMePMR1E/38UoArgCcOdUyinl93eOAIrABmSpoW/iq9GlgWdcwy4B/C1kGnAZXtxQrxFpaJ/hRYb2bfO8Qx48LjkDSf4N+2rI/SN1xSdvsyQSXqe1GHJez5RTjkL71EPr8Iy4AbwuUbgGc7OSaWv9W4kHQhcDtwqZnVHeKYWP4W4pW+yDqzyw9x3YQ9v9BHgQ1mVtLZzkQ+v25JdO18f3kRtPr5G0GLi38Jt90M3BwuC7gv3L8GmNeHaTuTIDv9LlAYvi6KSt8twFqCViJvAB/uw/RND6+7OkxDv3p+4fUzCQLByIhtCXt+BAFsJ9BM8Cv4M0A+8BKwMXzPC4+dACw/3N9qH6VvE0H9QPvf4JLo9B3qb6GP0veL8G/rXYJgML4/Pb9w+8/a/+Yiju3z53ekLx9yxDnnXLd4UZVzzrlu8cDhnHOuWzxwOOec6xYPHM4557rFA4dzzrlu8cDhXD+nYOTe3yY6Hc6188DhnHOuWzxwONdLJF0n6a1wHoUfS0qWVCPpbklvS3pJ0ujw2DmS3oiY2yI33H6UpBfDwRbfljQj/PgsSb9SMB/GI+293J1LBA8czvUCSbOAvycYoG4O0ApcCwwnGB/rJOBPwL+Fp/wcuN3MTiDo7dy+/RHgPgsGW/wwQe9jCEZEvg2YTdC7+Iw435Jzh5SS6AQ4N0icC5wMrAgzA8MIBilsY/+Adg8DT0saCeSY2Z/C7Q8BvwzHKJpoZs8AmFkDQPh5b1k4vlE4c1wB8Je435VznfDA4VzvEPCQmX3tgI3S16OOO9wYP4crfmqMWG7F/++6BPKiKud6x0vAJySNgY75w6cS/B/7RHjMJ4G/mFklsE/SWeH264E/WTDHSomky8LPSJeU2Zc34Vws/FeLc73AzNZJ+leCmduSCEZF/QJQCxwnaRVQSVAPAsGw6UvCwLAZuDHcfj3wY0nfCj/jyj68Dedi4qPjOhdHkmrMLCvR6XCuN3lRlXPOuW7xHIdzzrlu8RyHc865bvHA4Zxzrls8cDjnnOsWDxzOOee6xQOHc865bvn/Nx6RCJTeBwMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test the network\n",
    "score = model.evaluate(input_X_test, output_Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IUIcenlMP3S"
   },
   "source": [
    "Exploring Training Hyperparameters\n",
    "-------------\n",
    "\n",
    "You can explore the role of various hyperparameters to see how you can further improve the MLP model's performance on the MNIST dataset. \n",
    "\n",
    "For example, if you increase the number of epochs for the dropout network to 250, you will see that the test and train accuracy errors will converge (accuracy closer to 97% for both training and test), which means that we have achieved the best tradeoff between training and testing.\n",
    "\n",
    "You can carry out many additional simulations on hypeparameter exploration where you can try for example:\n",
    "\n",
    "- different number of epochs\n",
    "- different learning rate\n",
    "- different number of hidden nodes \n",
    "- different proportion of dropout rates \n",
    "- different optimisers in addition to SGD (e.g. RMSprop, Adam) \n",
    "- different batch size \n",
    "\n",
    "This final exercise will constitute the first neural network coursework. See Coursework specification documenty for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPKj5NAdMP3T"
   },
   "source": [
    "Conclusions\n",
    "-------------\n",
    "\n",
    "With this tutorial we have practiced the training of both a Simple Perceptron, and a Multi-Layer Perceptron, with a benchmark dataset containing images of handwritten numbers.\n",
    "This helped us understand how to load the datase, visualise it, and visualise the training history and the effects of adding hidden layers and then adding weight dropout.\n",
    "\n",
    "**Copyright (c)** 2022 Angelo Cangelosi, MIT License. Code and examples adapted from Gulli & Pal (2017) Deep Learning with Keras. Punkt Publishing. With further contribution from Wenjie Huang."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DATA70132_Lab5b_Keras_MLP_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
